{"nbformat":4,"nbformat_minor":0,"metadata":{"celltoolbar":"Edit Metadata","colab":{"name":"Regressao - Exercicio.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":true,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"207px"},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"cells":[{"cell_type":"markdown","metadata":{"id":"gTh4frkWbKmm"},"source":["# <center>Regressão - Exercício</center>\n","___"]},{"cell_type":"markdown","metadata":{"id":"6ZTb_gkObKpE"},"source":["<a id=\"exercicio\"></a>\n","## 6. Exercícios\n","\n","Esse notebook contém os exercícios da aula de regressão. Siga as instruções para aplicar o que foi aprendido nessa aula para outra base de dados para tentar prever os preços de carros. Essa base de dados foi disponibilizada junto com o notebook.\n","\n","Vamos começasr lendo os dados."]},{"cell_type":"code","metadata":{"id":"quiT1EFyHNHO"},"source":["import pandas as pd\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error\n","import lightgbm as lgb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"La9W9UKwbKpF"},"source":["cars_df = pd.read_csv(\"./data/OLX_Car_Data.csv\", encoding = 'unicode_escape')\n","\n","cars_df.describe(include='all')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cOiFmnJfbKpK"},"source":["Utilizando o método ```describe``` conseguimos ver algumas informações necessárias para fazer uma limpeza básica nos nossos dados. Veja abaixo."]},{"cell_type":"code","metadata":{"id":"VxzMk5VgbKpK"},"source":["# renomeando as colunas para remover os espaços\n","cars_df.rename(columns = {'KMs Driven':'KMs_Driven', \n","                          'Registered City':'Registered_City', \n","                          'Transaction Type':'Transaction_Type'},\n","               inplace = True)\n","\n","# Já que a coluna Model tem muitas categorias, vamos nomear todas com menos de 400 observações de 'Outros'\n","models = ['Alto', 'Corolla GLI', 'Mehran VX', 'Mehran VXR', 'Vitz', 'Bolan', 'Cuore', 'Corolla XLI', 'Mira']\n","cars_df.loc[~cars_df['Model'].isin(models),'Model'] = 'Outros'\n","\n","# removendo valores nulos\n","cars_df.dropna(axis=0, inplace=True)\n","\n","# removendo outliers\n","low = 0.05\n","high = 0.95\n","quant_df = cars_df.quantile([low, high])\n","cars_df = cars_df[(cars_df.KMs_Driven < quant_df.loc[high, \"KMs_Driven\"]) & \n","                  (cars_df.KMs_Driven > quant_df.loc[low, \"KMs_Driven\"]) &\n","                  (cars_df.Price < quant_df.loc[high, \"Price\"]) & \n","                  (cars_df.Price > quant_df.loc[low, \"Price\"]) &\n","                  (cars_df.Year < quant_df.loc[high, \"Year\"]) & \n","                  (cars_df.Year > quant_df.loc[low, \"Year\"])]\n","\n","# transformando as variáveis binárias\n","cars_df['is_new'] = 1\n","cars_df.loc[cars_df.Condition == 'Used', 'is_new'] = 0\n","cars_df.drop(['Condition'], axis=1, inplace=True)\n","\n","cars_df['is_cash'] = 0\n","cars_df.loc[cars_df.Transaction_Type=='Cash', 'is_cash'] = 1\n","cars_df.drop('Transaction_Type', axis=1, inplace=True)\n","\n","# aplicando o One Hot Encoding\n","cars_df = pd.concat([cars_df.drop(\"Brand\", axis=1), pd.get_dummies(cars_df.Brand, prefix='Brand')], axis=1)\n","cars_df = pd.concat([cars_df.drop(\"Fuel\", axis=1), pd.get_dummies(cars_df.Fuel, prefix='Fuel')], axis=1)\n","cars_df = pd.concat([cars_df.drop(\"Registered_City\", axis=1), pd.get_dummies(cars_df.Registered_City, prefix='RCity')], axis=1)\n","cars_df = pd.concat([cars_df.drop(\"Model\", axis=1), pd.get_dummies(cars_df.Model, prefix='Model')], axis=1)\n","\n","cars_df.describe(include='all')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cxdwDWukbKpM"},"source":["y, X = cars_df.Price, cars_df.drop('Price', axis=1)\n","\n","print(\"X\", X.shape)\n","print(\"y\", y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HayLh69ebKpP","scrolled":true},"source":["seed = 1\n","\n","# separando treino e teste\n","X_training, X_test, y_training, y_test = train_test_split(X, y, random_state=seed, test_size=0.25) #, stratify=y)\n","print(\"Test set X\", X_test.shape)\n","print(\"Test set y\", y_test.shape)\n","\n","# separando treino e validação\n","X_train, X_val, y_train, y_val = train_test_split(X_training, y_training, random_state=seed,\n","                                                  test_size=0.33) #, stratify=y_training)\n","\n","print(\"Train set X\", X_train.shape)\n","print(\"Train set y\", y_train.shape)\n","print(\"Validation set X\", X_val.shape)\n","print(\"Validation set y\", y_val.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G5YWY7RfbKpU"},"source":["#### Exercício 1\n","\n","**Substitua as lacunas** para treinar um modelo de *random forest* com validação cruzada e *grid search*. O *grid search* deve variar, pelo menos, os parâmetros *n_estimators* e *max_depth*, mas você pode incluir outros. Após o treino, crie o *dataframe* ```cv_results``` com os resultados de cada iteração e o dicionário ```cv_best_params``` com os valores da melhor combinação de parâmetros."]},{"cell_type":"code","metadata":{"exid":"1","id":"Ky0nFCGLz_Hq"},"source":["# Random Forest com validação cruzada e Grid Search\n","\n","# definindo os valores possíveis dos parâmetros a serem testados\n","params = {}\n","\n","# criando o objeto do modelo com RandomForestRegressor\n","rf_model_cv_gs = ________________()\n","\n","# criando o objeto do grid search com GridSearchCV\n","grid_search = ___________(rf_model_cv_gs, param_grid=params, return_train_score=True, scoring='neg_root_mean_squared_error')\n","\n","# treinando o modelo com o grid search\n","grid_search.________(X_training, y_training)\n","\n","# pegando os resultados da validação cruzada (cv_results)\n","cv_results = pd.DataFrame(grid_search.________)\n","\n","# pegando e imprimindo a melhor combinação de hiperparâmetros\n","cv_best_params = grid_search.________\n","print('\\n Best hyperparameters:')\n","print(cv_best_params)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xoUuVKOE1MdZ"},"source":["#### Exercício 2\n","\n","**Substitua as lacunas** para treinar o modelo final de *random forest* com os melhores parâmetros obtidos no *grid search* do exercício anterior."]},{"cell_type":"code","metadata":{"exid":"2","id":"kl1YtSsKbKpV","scrolled":false},"source":["# imprimindo o score médio nas bases de treino\n","print(\"Average accuracy on train set: {:.3f} +/- {:.3f}\".format(cv_results[cv_results.rank_test_score == 1].mean_train_score.values[0],\n","                                                                     cv_results[cv_results.rank_test_score == 1].std_train_score.values[0])) \n","# imprimindo o score médio nas bases de validação\n","print(\"Average accuracy on validation set: {:.3f} +/- {:.3f}\".format(cv_results[cv_results.rank_test_score == 1].mean_test_score.values[0],\n","                                                                     cv_results[cv_results.rank_test_score == 1].std_test_score.values[0])) \n","\n","# configurando o modelo com a melhor combinação de hiperparâmetros\n","rf_model_cv_gs.________(n_estimators = cv_best_params['n_estimators'],\n","                        max_depth = cv_best_params['max_depth'],\n","                        ______)\n","\n","# treinando um modelo com a melhor combinação de hiperparâmetros\n","rf_model_cv_gs.________(X_training, y_training)\n","best_model_params = rf_model_cv_gs.get_params()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ORZjy1W63W-9"},"source":["#### Exercício 3\n","\n","**Substitua as lacunas** para obter um *dataframe* com a importância de cada variável do modelo de *random forest*."]},{"cell_type":"code","metadata":{"exid":"3","id":"QKwOpM1wbKpa"},"source":["# desenhando o gráfico de impoartância de variáveis\n","features = X_training.______\n","importances = rf_model_cv_gs.______\n","indices = np.argsort(importances)\n","\n","feature_importances_df = pd.DataFrame({'features': features,\n","                                       'importances': importances})\n","\n","plt.title('Feature Importances')\n","plt.barh(range(len(importances[indices][-15:])), importances[indices][-15:], color='b', align='center')\n","plt.yticks(range(len(importances[indices][-15:])), [features[i] for i in indices[-15:]])\n","plt.xlabel('Relative Importance')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LhsZo64LHNHU"},"source":["#### Exercício 4\n","\n","**Substitua as lacunas** para calcular o RMSE do modelo de *random forest* final na base de teste."]},{"cell_type":"code","metadata":{"exid":"4","id":"DVvyM-PeHNHV"},"source":["y_test_pred_rf = rf_model_cv_gs.______(X_test)\n","rmse_test_rf = math.sqrt(mean_squared_error(y_test, ______))\n","print(rmse_test_rf)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-ljTj09XbKpc"},"source":["#### Exercício 5\n","\n","**Substitua as lacunas** para treinar um modelo de *Light GBM* com validação cruzada e *grid search*. O *grid search* deve variar, pelo menos, os parâmetros *learning_rate* e *n_estimators*, mas você pode incluir outros. Após o treino, crie o *dataframe* ```cv_results``` com os resultados de cada iteração e o dicionário ```cv_best_params``` com os valores da melhor combinação de parâmetros."]},{"cell_type":"code","metadata":{"exid":"5","id":"6f4c8q32bKpd","scrolled":true},"source":["# Light GBM com validação cruzada e Grid Search\n","\n","# definindo os valores possíveis dos parâmetros a serem testados\n","# params = {'max_depth': [10, 50, 100],\n","#           'learning_rate': [0.01, 0.03, 0.1, 0.5],\n","#           'num_iterations': [100, 200, 500],\n","#           'min_data_in_leaf': [20, 50],\n","#           'min_gain_to_split': [0., 1, 5]}\n","params = {____}\n","\n","# criando o objeto do modelo com XGBClassifier\n","lgb_model_cv_gs = lgb.__________()\n","\n","# criando o objeto do grid search com GridSearchCV\n","grid_search = _________(lgb_model_cv_gs, param_grid=params, return_train_score=True, scoring='neg_root_mean_squared_error')\n","\n","# treinando o modelo com o grid search\n","grid_search.______(X_training, y_training)\n","\n","# pegando os resultados da validação cruzada (cv_results)\n","cv_results = pd.DataFrame(grid_search._________)\n","\n","# pegando e imprimindo a melhor combinação de hiperparâmetros\n","cv_best_params = grid_search._________\n","print('\\n Best hyperparameters:')\n","print(cv_best_params)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hni7HUd14BBg"},"source":["#### Exercício 6\n","\n","**Substitua as lacunas** para treinar o modelo final de *light GBM* com os melhores parâmetros obtidos no *grid search* do exercício anterior."]},{"cell_type":"code","metadata":{"exid":"6","id":"op7r1CM6346h"},"source":["# imprimindo o score médio nas bases de treino\n","print(\"Average accuracy on train set: {:.3f} +/- {:.3f}\".format(cv_results[cv_results.rank_test_score == 1].mean_train_score.values[0],\n","                                                                     cv_results[cv_results.rank_test_score == 1].std_train_score.values[0]))\n","\n","# imprimindo o score médio nas bases de validação\n","print(\"Average accuracy on validation set: {:.3f} +/- {:.3f}\".format(cv_results[cv_results.rank_test_score == 1].mean_test_score.values[0],\n","                                                                     cv_results[cv_results.rank_test_score == 1].std_test_score.values[0]))\n","\n","# configurando o modelo com a melhor combinação de hiperparâmetros\n","lgb_model_cv_gs.__________(learning_rate = cv_best_params['learning_rate'],\n","                           n_estimators = cv_best_params['n_estimators'],\n","                           ______)\n","\n","# treinando um modelo com a melhor combinação de hiperparâmetros\n","lgb_model_cv_gs._____(X_training, y_training)\n","best_model_params = lgb_model_cv_gs.get_params()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gdhCQ7SYbKph"},"source":["#### Exercício 7\n","\n","**Substitua as lacunas** para obter um *dataframe* com a importância de cada variável do modelo de *light GBM*."]},{"cell_type":"code","metadata":{"exid":"7","id":"ehKrQQ7xbKpi"},"source":["# desenhando o gráfico de impoartância de variáveis\n","features = X_training.______\n","importances = lgb_model_cv_gs.______\n","indices = np.argsort(importances)\n","\n","feature_importances_df = pd.DataFrame({'features': features,\n","                                       'importances': importances})\n","\n","plt.title('Feature Importances')\n","plt.barh(range(len(importances[indices][-15:])), importances[indices][-15:], color='b', align='center')\n","plt.yticks(range(len(importances[indices][-15:])), [features[i] for i in indices[-15:]])\n","plt.xlabel('Relative Importance')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UAiQT7z1HNHX"},"source":["#### Exercício 8\n","\n","**Substitua as lacunas** para calcular o RMSE do modelo de *light GBM* final na base de teste."]},{"cell_type":"code","metadata":{"exid":"8","id":"URuUzkA_HNHY"},"source":["y_test_pred_lgb = lgb_model_cv_gs.______(X_test)\n","rmse_test_lgb = math.sqrt(mean_squared_error(y_test, ______))\n","print(rmse_test_lgb)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aVpe_IBpbKpq"},"source":["Os resultados dos modelos criados até aqui fazem sentido para você?\n","\n","Vamos desenhar gráficos para comparar as duas previsões como fizamos com os dados de **boston**, e usá-los para responder as demais perguntas:"]},{"cell_type":"code","metadata":{"id":"sRUpxmzZbKpr"},"source":["# Desenhando o gráfico de valores previstos por valores reais para ambos os modelos\n","\n","plt.figure(figsize=(16,10))\n","plt.title('Pakistan car prices - Predicted vs Real',fontsize=20)\n","df = pd.DataFrame({'real':y_val,'Random Forest':rf_model_cv_gs.predict(X_val),\n","                   'LGBM':lgb_model_cv_gs.predict(X_val)})\n","df = df.sample(200)\n","df.sort_values(by=['real'],ascending=True,inplace=True)\n","df = df.reset_index(drop=True)\n","plt.plot(df)\n","plt.legend(['Real price','Predicted RF price','Predicted LGBM price'],fontsize=20)\n","plt.ylabel('$ Price',fontsize=20)\n","plt.xlabel('Observations ordered by price',fontsize=20)\n","plt.show()\n","\n","plt.figure(figsize=(16,10))\n","plt.title('Pakistan car prices - Predicted vs Real',fontsize=20)\n","plt.scatter(x=df['real'],y=df['Random Forest'],c='y')\n","plt.scatter(x=df['real'],y=df['LGBM'],c='g')\n","plt.plot([0,1750000],[0,1750000],'k--')\n","# plt.axis([0,1750000,0,1750000])\n","plt.legend(['Real price','Predicted RF price','Predicted LGBM price'],fontsize=20)\n","plt.xlabel('Real price',fontsize=20)\n","plt.ylabel('Predicted price',fontsize=20)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hIsLsboObKpx"},"source":["#### Exercício 9\n","*(Resposta aberta, não contabilizara pontos, o objetivo é refletir sobre a questão/tópico)*\n","\n","Qual modelo parece ter menos *over-fitting*? Explique"]},{"cell_type":"code","metadata":{"id":"ffzlYuZ3bKpx"},"source":["# suas respostas\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cy87yOZWMvcs"},"source":["#### Exercício 10\n","*(Resposta aberta, não contabilizara pontos, o objetivo é refletir sobre a questão/tópico)*\n","\n","Qual modelo faz a melhor previsão dos preços dos carros em cada faixa de preço?"]},{"cell_type":"code","metadata":{"id":"KBm0QCJvM2f0"},"source":["# suas respostas\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OoCEJhofM24B"},"source":["#### Exercício 11\n","*(Resposta aberta, não contabilizara pontos, o objetivo é refletir sobre a questão/tópico)*\n","\n","Qual modelo vocês utilizaria afinal? Explique"]},{"cell_type":"code","metadata":{"id":"VMzL5rF6M6VG"},"source":["# suas respostas\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aa_c_ncwHNHc"},"source":[""],"execution_count":null,"outputs":[]}]}