{"nbformat":4,"nbformat_minor":0,"metadata":{"celltoolbar":"Edit Metadata","colab":{"name":"Regressao - Teoria.ipynb","provenance":[],"collapsed_sections":["qy8-aReVbKne","ell_AsFEbKoI"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":true,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"207px"},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"cells":[{"cell_type":"markdown","metadata":{"id":"gTh4frkWbKmm"},"source":["# <center>Regressão - Teoria</center>\n","___"]},{"cell_type":"markdown","metadata":{"id":"HaiL6EjTbKmp"},"source":["## Conteúdo\n","1. [Relembrando](#recap) <br>\n","2. [Definição do Problema](#problem_def) <br>\n","3. [Análise inicial](#initial_analysis) <br>\n","4. [Separação de Treino e Teste](#split) <br>\n","5. [Modelagem](#modeling) <br>\n","6. [Avaliação do Modelo](#eval) <br>\n","[Saiba Mais](#digdeeper)\n","\n","<a id=\"dsprecap\"></a>\n","## Data Science Pipeline (DSP)\n","1. Definição do Problema / Definição do Escopo\n","2. Definição das Métricas de Sucesso\n","3. Definição dos Dados Necessários\n","4. Aquisição de Dados\n","5. Pré-processamento de Dados\n","6. Análise Exploratória de Dados (E.D.A.)\n","7. <i>Feature Engineering</i>\n","8. Construção e Avaliação do Modelo\n","9. Comunicação dos Resultados\n","10. Implantação\n","11. Monitoramento e Manutenção\n","\n","**Essa aula tratará principalmente do passo 8, para os casos de modelos regressivos.**"]},{"cell_type":"markdown","metadata":{"id":"q-ZbQxNWbKmq"},"source":["<a id=\"recap\"></a>\n","## 1. Relembrando"]},{"cell_type":"markdown","metadata":{"id":"xob1tmdHbKmt"},"source":["Olá! Na última aula nos exploramos os problemas de classificação. Já sabemos como construir modelos que indicam, por exemplo, se vai chover ou não amanhã, ou se o resultado de uma partida de futebol gaélico (ou futebol irlandês) será um empate, vitória ou derrota para um dos times.\n","\n","<img src = http://image.vovworld.vn/w730/uploaded/vovworld/asfzyrvslys/2016_04_22/it%20had%20goals,%20it%20had%20fights,%20it%20had%20dubious%20decisions,%20it%20had%20end-to-end%20football%20and%20even%20had%20blanket%20defences%20at%20times.jpg width = 400>\n","\n","Achando que já sabe resolver todos os problemas de <i>machine learning</i> já? Muita calma nessa hora! Imagine que você tem uma filha e quer prever com qual idade ela terá o primeiro filho. Esse não é um problema de classificação: a resposta para essa questão é um número e não uma classe. Então a previsão do seu modelo pode estar entre, digamos, 10 anos (torcemos que não) e 50 anos.\n","\n","Em resumo, quando a pergunta deixa de ser _qual_ e passa a ser _quanto_, então você tem um problema de regressão na sua frente.\n","\n","Mais uma vez, utilizaremos a biblioteca _open source_ do python sci-kit learn (**sklearn**)."]},{"cell_type":"markdown","metadata":{"id":"MmA_RcGWbKmu"},"source":["<a id=\"problem_def\"></a>\n","## 2. Definição do Problema"]},{"cell_type":"markdown","metadata":{"id":"R1VfZCaWbKmv"},"source":["Imagine a seguinte situação hipotética (ou não): em uma tarde ensolarada do final dos anos 1970 você está andando com seu cachorro pelas ruas do centro de Boston, nos EUA. Seu cachorro para pra fazer aquilo que ele saiu pra fazer, e você, esperando ele terminar, avista uma bela casa de dois andares. Naturalmente, você pensa: _\"Nossa, olha aquela casa! Com um jardim daquele tamanho, eu nem precisaria levar meu cachorro para passear. Quanto será que uma casa dessa custa?\"_ Essa é uma pergunta pertinente, mas que demandaria conhecimento e experiência do mercado imobiliário para adivinhar o preço daquela casa nos anos 70.\n","</br>\n","\n","\n","<img src = https://4pfoten-on-tour.de/wp-content/uploads/2018/05/dog-3320058_1920.jpg width = 400>\n","\n","Agora digamos que você é uma pessoa no século 21 e está aprendendo sobre _machine learning_ - parece familiar? - e, mais do que isso, você está pensando _\"qual seria o lugar que eu viveria se eu estivesse nos anos 70 e tivesse que escolher um lugar que eu pudesse andar com meu cachorro todos os dias?\"_ A resposta pra essa pergunta só pode ser... Boston, certo? Bom, pelo menos nessa situação hipotética é o que assumiremos. Então você abre o mapa, começa a olhar as casas e se pergunta _\"será que eu conseguiria comprar essa casa na época?\"_ É aí que você lembra das suas aulas de _machine learning_ e começa a fazer um modelo para prever o valor monetário da casa dos seus sonhos.\n","\n","É isso que vamos fazer hoje! Vamos utilizar uma base de dados do _sklearn_ chamada **boston**, que contem informações do mercado imobiliário da cidade de mesmo nome nos anos 70, como o preço do imóvel, indicadores sociais, configurações do espaço do imóvel e assim por diante.\n","\n","Então vamos tentar ensinar nossa máquina a prever quanto custa um imóvel baseado nessas informações que nós temos. E, dado que a pergunta agora é _quanto_ ao invés de _qual_, nosso problema é de regressão.\n","\n","Pronto? Vamos **começar**!"]},{"cell_type":"code","metadata":{"id":"ah8sMWkFbKmw"},"source":["# Importando a base de dados\n","from sklearn import datasets\n","estate_df = datasets.load_boston()\n","\n","X, y = estate_df.data, estate_df.target\n","\n","print(\"X\", X.shape)\n","print(\"y\", y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6BioFQRWbKm3"},"source":["Conseguimos ver que temos 13 variáveis (_features_) que descrevem 506 imóveis. Veremos a frente que essa razão de _observações_/_variáveis_ é apropriada.\n","\n","As bases de dados (_datasets_) do ```scikit-learn``` são objetos da class Bunch, que contem os dados em si, mas também informações adicionais sobre eles. Esse tipo de informação é chamado de metadados (_metadata_), que significa \"dados sobre os dados\". Podemos entender essa classe como algo similar aos dicionários do python, com a vantagem de podermos acessar os atributos com um ponto (dataset.atributo ao invés de dataset\\['atributo'\\]). Assim como nos dicionários, podemos ver todas as informações no objeto Bunch usando ```print(dataset.keys())```.\n","\n","No código abaixo pegamos a descrição dos dados que vamos usar na aula de hoje:"]},{"cell_type":"code","metadata":{"id":"yhojCBlYbKm4","scrolled":false},"source":["# Imprimindo a descrição da base de dados\n","print(estate_df.DESCR)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f_lJ_BYobKm_"},"source":["<a id=\"initial_analysis\"></a>\n","## 3. Análise Inicial"]},{"cell_type":"markdown","metadata":{"id":"9jiQCuCfbKnA"},"source":["Para começar, é importante lembrar que o _dataset_ utilizado nessa aula é adquirido através da biblioteca _scikit-learn_. A maioria dos _datasets_ do pacote, chamados de *toy datasets* (base de dados de brinquedo), são utilizados para usos educacionais e como comparativos. Dessa forma, eles normalmente **já estão com uma certa qualidade e passaram por alguns processos de pré-processamento**. É importante notar que em _datasets_ de problemas reais é preciso passar por todo os passos da metodologia antes da modelagem.\n","\n","\n","### 3.1. Classificação x Regressão\n","Para falar dos algoritmos de regressão, é importante começarmos discutindo as diferenças entre eles e as técnicas de classificação. ***A principal diferença está de fato na variável resposta. Na classificação ela é categorica (discreta), enquanto na regressão ela é um valor numérico (contínuo).***\n","\n","Em machine learning, os algoritmos regressivos tentam estimar uma função (f) que mapeia as variáveis de entrada (x) a uma variável resposta (y) numérica, ou contínua. Nesse caso, y é um valor real que pode ser inteiro ou decimal. Por isso, os problemas nos quais se aplicam um modelo de regressão estão relacionados a quantidade ou tamanho.\n","\n","No exemplo que usaremos aqui, nosso objetivo é prever o preço de um imóvel baseado em um conjunto de variáveis. Mais uma vez, nossa pergunta aqui é _quanto_ e não _qual_!!!\n","\n","Com isso, dada a diferença da variável resposta, a forma que avaliamos a qualidade de um modelo regressivo é diferente do que fazemos para modelos classificatórios. Para os modelos de classificação podemos utilizar como métricas a área sob a curva ROC, a acurácia ou o Log-Loss, enquanto para os modelos de regressão costumamos utilizar o MSE (sigla em inglês para erro quadrático médio), RMSE (raiz do erro quadrático médio), R² (R-quadrado) ou R² ajustado.\n","\n","\n","\n","### 3.2 Representatividade do domínio\n","Na última aula, foi falado do problema de desbalanceamento de classes para problemas de classificação, que é muito importante naquele caso. Nos problemas de regressão, temos um outro problema igualmente importante, a representatividade do domínio.\n","No *dataset* de Boston, por exemplo. os preços das casas vão de US\\$ 5,000 a US\\$ 50,000. Quando separamos os dados em treino e teste, é importante verificarmos que os preços na base de treino representam de forma justa os dados completos, para que tenhamos exemplos de treino em (quase) todo o domínio da variável resposta. É isso que chamamos de representatividade do domínio. Vamos ver a distribuição dos preços na nossa base!\n"]},{"cell_type":"code","metadata":{"id":"onaDJ9SibKnB"},"source":["%matplotlib inline\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","plt.figure()\n","df_target = pd.DataFrame(estate_df.target)\n","df_target.groupby(pd.cut(df_target[0], np.arange(0,51,5))).count().plot(kind='bar', legend=False)\n","plt.title('Distribuição dos preços das casas de Boston')\n","plt.ylabel('Quantidade de casas')\n","plt.xlabel('Faixa de preço')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gmgcyuRcbKnJ"},"source":["Como pudemos ver, a distribuição de preços não é plana, então é boa prática garantir que os *datasets* de treino e teste têm distribuição similar."]},{"cell_type":"markdown","metadata":{"id":"hZMpLJIZnblE"},"source":["### 3.3 Como converter um problema de regressão em um problema de classificação?\n","\n","Por fim, mas não menos importante, vale mencionar que conseguimos transformar um problema de regressão em um de classificação em alguns casos. Por exemplo, a quantidade a ser prevista poderia ser transformada em grupos discretos. A própria visualização utilizada no gráfico acima já foi feita com barras que representam intervalos fixados, então a gente consegue analisá-los em um domínio discreto (olha a classificação aqui!). Isso normalmente é chamado de discretização e a variável resposta pssa a ser classificada com rótulos que tem uma relação de ordem. Essa abordagem pode ser bastante poderosa em alguns problemas reais."]},{"cell_type":"markdown","metadata":{"id":"9DeQ1g-2bKnL"},"source":["<a id=\"split\"></a>\n","## 4. Separação dos *datasets* de treino e teste\n","\n","A teoria da quebra em treino, teste e validação foi tratado na última aula e é a mesma para os casos de regressão. É um dos conceitos mais importantes do nosso pipeline de modelagem. Caso não se recorde dos conceitos tratados nessa seção, volte na aula anterior."]},{"cell_type":"markdown","metadata":{"id":"jn6uFtrIbKnO"},"source":["### 4.1. Código Python"]},{"cell_type":"markdown","metadata":{"id":"3DuuVSTIbKnP"},"source":["#### 4.1.1. Separação de treino e teste\n","Primeiramente separamos o conjunto de teste."]},{"cell_type":"code","metadata":{"id":"aBr1CZW4bKnR"},"source":["# importando a função train_test_split\n","from sklearn.model_selection import train_test_split\n","\n","# configurando a semente aleatória para reprodutibilidade dos resultados\n","# a mesma semente será utilizada em demais partes do código\n","seed = 10\n","\n","# usando a função train_test_split para criar o dataset de teste\n","# random_state  é utilizado para a geração dos números aleatórios, por isso passamos a semente\n","# test_size define o tamanho do dataset de teste e pode ser um inteiro do número de observações ou a proporção delas\n","# stratify é utilizado para garantir que a distribuição dos dados seja parecida nos dados de treino e teste\n","X_training, X_test, y_training, y_test = train_test_split(X, y, random_state=seed, test_size=0.25) #, stratify=y)\n","\n","print(\"Test set X\", X_test.shape)\n","print(\"Test set y\", y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5ibnDlMrbKnY"},"source":["#### 4.1.2. Separação de treino e validação\n","Então dividimos as obsevações resultantes do treino para separar novamente no conjunto de validação."]},{"cell_type":"code","metadata":{"id":"TA4Tp6Y7bKnY"},"source":["# o mesmo do anterior, mas separando a partir da base de treino apenas\n","X_train, X_val, y_train, y_val = train_test_split(X_training, y_training, random_state=seed,\n","                                                  test_size=0.33) #, stratify=y_training)\n","\n","print(\"Train set X\", X_train.shape)\n","print(\"Train set y\", y_train.shape)\n","print(\"Validation set X\", X_val.shape)\n","print(\"Validation set y\", y_val.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TphrZONEbKnc"},"source":["Assim como na última aula, podemos usar a imagem abaixo como referência, então em cada uma das variáveis, temos:\n","\n","- **X_test** e **y_test**: conjunto de teste (vermelho)\n","- **X_training** e **y_training**: conjunto auxiliar de treino (verde superior) para o método de holdout (com validação cruzada)\n","- **X_train** e **y_train**: conjunto de treino (verde inferior) para treino sem validação cruzada\n","- **X_val** e **y_val**: conjunto de validação (amarelo) para avaliar os modelos sem validação cruzada\n","\n","<img src=\"https://cdn-images-1.medium.com/max/1200/1*4G__SV580CxFj78o9yUXuQ.png\" alt=\"cv\" style=\"width: 600px;\"/>"]},{"cell_type":"markdown","metadata":{"id":"HnZMgQKfbKnc"},"source":["<a id=\"eval\"></a>\n","## 6. Avaliação dos modelos - Métricas\n","\n","Já aprendemos como separar nossos *datasets* em treino, teste e validação. Agora, precisamos entender como escolhemos os melhores modelos. Assim como fizemos no modelo de classificação, vamos fazer isso através de métricas de erro, mas essas métricas são diferentes daquelas usadas nas aulas anteriores. Apresentamos a seguir as métricas dos modelos regressivos, com as siglas em inglês, como normalmente são utilizados:\n","* MAE (erro absoluto médio)\n","* MSE (erro quadrático médio)\n","* RMSE (raiz do erro quadrático médio)\n","* R² (R quadrado)\n","\n","### 6.1 MAE (erro absoluto médio)\n","\n","MAE é a média do valor absoluto da diferença entre o valor previsto e o valor real. O MAE é uma métrica linear, o que significa que cada diferença tem um peso igual na média. Por exemplo, a diferença entre 0 e 10 será o dobro de uma diferença entre 5 e 0. Porém, o mesmo não é verdade para o RMSE, que discutiremos em breve. Sua fórmula matemática é:\n","\n","![Imgur](https://cdn-images-1.medium.com/max/800/1*8DXbECB9pnKxTpIvuVD-vg.png)\n","\n","### 6.2 MSE (erro quadrático médio)\n","\n","O erro qudrático médio (MSE) é como o MAE, mas elevamos as diferenças ao quadrado antes de somá-las ao invés que calcular o valor absoluto. Uma vez que as diferenças são elevadas ao quadrado, essa métrica penaliza mais os *outliers*. Sua fórmula matemática está a seguir:\n","\n","![Imgur](https://cdn-images-1.medium.com/max/300/1*3wB5otkgKEiv9X6Gdd0r2Q@2x.png)\n","\n","\n","### 6.3 RMSE (raiz do erro quadrático médio)\n","\n","Essa é uma das métricas mais utilizadas nos modelos de regressão. Como o MSE, essa métrica também penaliza os *outliers*. Entretanto, ele tem a vantagem de ter a mesma unidade da variável resposta, ao contrário do MSE, o que torna ele mais fácil de ser interpretado. Por exemplo, com o preço das casas em dólar, teríamos o RMSE também em dólar. A equação matemática está abaixo:\n","\n","![Imgur](https://cdn-images-1.medium.com/max/1000/1*qz8jRMxmMEwNsFh0Cs5XfQ.png)\n","\n","### 6.4 R² (R quadrado)\n","\n","Uma dificuldade de utilizar o MSE ou RMSE é não ter uma indicação clara pelo valor da métrica. Se eu te disser que temos um MSE de 11,7 você diria que é bom ou ruim? Na verdade, é muito difícil dizer se nosso modelo é bom ou ruim apenas pelos valores das métricas de MSE ou RMSE, elas servem mais para comparação. Dessa forma, seria bom se tivessemos uma métrica base para fazer essa comparação.\n","O coeficiente de determinação, ou R² é uma métrica bastante relacionada ao RMSE, mas com a vantagem de não depender da escala dos valores previstos, o que significa que independentemente dos valores serem grandes ou pequenos, o R² sempre estará entre -∞ e 1.\n","\n","Quando o R² for negativo, significa que o modelo é pior do que prever utilizando a média.\n","\n","![Imgur](https://cdn-images-1.medium.com/max/300/1*iqUOveJbbKk7-DHcQ0ZOnA@2x.png)\n","\n","O MSE do modelo é computado como mostramos anteriormente, enquanto o MSE de *baseline* é definido como:\n","\n","![Imgur](https://cdn-images-1.medium.com/max/300/1*SZVKM6G8v8veQPqmO1c2Aw@2x.png)\n","\n","com o y com a barra acima sendo a média do valor observado, ou real, yᵢ.\n","\n","De forma mais simples, o MSE do *baseline* pode ser entendido como o MSE que o modelo mais simples obteria. O modelo mais simples para um problema regressivo seria sempre utilizar a média de todas as observações. Dessa forma, um valor para o R² próximo a 1 indica um modelo com erro próximo a 0, e um R² próximo a 0 indica um modelo próximo do *baseline*.\n","\n","Em resumo, ***R² é a razão entre quão bom é o nosso modelo e quão bom é o modelo da média***.\n","\n","Como vimos, há diferentes métricas para determinar o erro associado a uma previsão de um problema de regressão que variam bastante entre elas. A escolha entre as métricas vai depender do dado e do problema com o qual vocês está lidando. Se seu dado é sensível a *outliers*, é melhor usar MAE ou MAPE. Se *outliers* não é um problema pra você, você pode usar o MSE ou o RMSE. A seguir há algumas páginas para melhor entendimento desses conceitos, mas é importante lembrar que a escolha da métrica de erro é de extrema importância para a modelagem!\n","\n","1. [Medium](https://medium.com/usf-msds/choosing-the-right-metric-for-machine-learning-models-part-1-a99d7d7414e4): Choosing the Right Metric for Evaluating Machine Learning Models\n","2. [Dataquest](https://www.dataquest.io/blog/understanding-regression-error-metrics/): Understanding Regression Error Metrics in Python"]},{"cell_type":"markdown","metadata":{"id":"-rXrsE0ybKnd"},"source":["<a id=\"modeling\"></a>\n","## 5. Modelagem"]},{"cell_type":"markdown","metadata":{"id":"oX-rcd1VbKnd"},"source":["### 5.1. Random Forest"]},{"cell_type":"markdown","metadata":{"id":"qy8-aReVbKne"},"source":["#### 5.1.1. Teoria\n","A floresta aleatória (em inglês, random forest) é um modelo baseado em diversas árvores de decisão. Mas não é apenas a média de diversas previsões feitas por árvores (que seriam *florestas*), pois esse método inclui dois conceitos chave que dão a parte **aleatória** do nome:\n","\n","- Amostragem aleatória das observações do treino ao construir as árvores\n","- Seleção de um subconjunto aleatório das *features* ao quebrar os nós\n","\n","A imagem a seguir mostrar uma interpretação visual dessas ideias:\n","\n","![Imgur](https://c.mql5.com/2/33/image1__1.png)\n","\n","Para mais detalhes sobre como as *random forests* funcionam, clique [aqui](https://medium.com/@williamkoehrsen/random-forest-simple-explanation-377895a60d2d) para ler um artigo (em inglês) do Medium sobre o método e [aqui](https://www.youtube.com/watch?v=D_2LkhMJcfY) para assistir um pequeno vídeo sobre o assunto."]},{"cell_type":"markdown","metadata":{"id":"Jff1qwrDbKnf"},"source":["#### 5.1.2. Código em Python e Avaliação\n","\n","Primeiro, precisamos instalar o pacote **ensemble** que contém as funções e objetos necessários para utilizarmos o *random forest*."]},{"cell_type":"code","metadata":{"id":"dsGh2I0ZbKng","scrolled":true},"source":["import sys\n","!{sys.executable} -m pip install ensemble"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kdfjhk81bKnn"},"source":["Agora, vamos importar tudo o que precisamos, começando, é claro, pelo ```RandomForestRegressor```. Depois, vamos importar algumas métricas que utilizaremos para avaliar nosso modelo de  ```sklearn.metrics```."]},{"cell_type":"code","metadata":{"id":"GMvghmm4bKno"},"source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.datasets import make_regression\n","from sklearn.metrics import (explained_variance_score, \n","                             mean_absolute_error, \n","                             mean_squared_error, \n","                             mean_squared_log_error,\n","                             r2_score)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H0TcoaLjbKns"},"source":["Agora vamos treinar nosso primeiro modelo de *Random Forest*. Não está animado?\n","\n","Isso se trata basicamente de: criar o objeto do modelo de *random forest* com seus hiperparâmetros. Já que estamos com um problema de regressão, vamos usar a classe ```RandomForestRegressor```. Você consegue ver os parâmetros disponíveis para criar esse objeto [aqui](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html).\n","\n","Os parâmetros mais importantes que usaremos nessa aula são:\n","- **n_estimators \\[padrão = 10\\]**: O número de árvores de decisão criadas pelo modelo\n","- **max_features \\[padrão = 'auto'\\]**: O número de *features* a serem consideradas ao procurar pela melhor quebra. Se não for passado um valor, é utilizado o número total de *features* por padrão\n","- **max_depth \\[padrão = None\\]**: A profundidade máxima das árvores. Se não for passado, os nós são expandidos até que todas as folhas sejam puras ou menores que min_sample_split\n","- **min_samples_split  \\[padrão = 2\\]**: O número mínimo de observações necessários para se fazer uma quebra em um nó\n","\n","Para começar, não vamos definir os hiperparâmetros, então o modelo será gerado com os valores padrões."]},{"cell_type":"code","metadata":{"id":"4CsiOZxpbKns"},"source":["##### RandomForest 1\n","# criando o objeto do modelo com RandomForestRegressor\n","rf_model_1 = RandomForestRegressor(random_state = seed)\n","\n","# treinando o modelo com os dados de treino\n","rf_model_1.fit(X_train, y_train)\n","\n","# prevendo com o modelo nos dados de validação\n","y_pred = rf_model_1.predict(X_val)\n","\n","# calculando e imprimindo algumas métricas\n","print(\"Score on training set: {:.3f}\".format(rf_model_1.score(X_train, y_train)))\n","print(\"Score on validation set: {:.3f}\".format(rf_model_1.score(X_val, y_val)))\n","y = [rf_model_1.score(X_train, y_train), \n","     rf_model_1.score(X_val, y_val)]\n","x = [\"Train Score\", \"Validation Score\"]\n","width = 1/2\n","plt.bar(x, y, width, color=\"blue\") \n","print(\"Explained variance score: {:.3f}\".format(explained_variance_score(y_val, y_pred)))\n","print(\"Mean absolute error (MAE): {:.3f}\".format(mean_absolute_error(y_val, y_pred)))\n","print(\"Mean squared error (MSE): {:.3f}\".format(mean_squared_error(y_val, y_pred)))\n","print(\"Mean squared log error (MSLE): {:.3f}\".format(mean_squared_log_error(y_val, y_pred)))\n","print(\"R² Score: {:.3f}\".format(r2_score(y_val, y_pred)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5ma28xeUbKnw"},"source":["É isso! Bem fácil treinar um modelo de *Random Forest* para regressão, não é?\n","\n","Como podemos ver, o modelo treinado tem um R² de 97,9% nos dados de treinos e 78,8% nos dados de validação, representando uma diferença de 19,1% entre eles.\n","\n","É bem clara a diferença do R² nos dois dados, sendo bem maior nos dados de treino, indicando um problema clássico de *overfitting*. Para lidar com isso, você poderá rodar a célula abaixo alterando os parâmetros para tentar diminuir a diferênça do R² no treino e na validação. Tome cuidado para não reduzir demais as duas também, é melhor ter um modelo com *overfitting* que faz uma boa previsão do que um modelo que não tem previsões boas no treino nem na validação.\n","\n","Tenha em mente as seguintes características de cada um dos hiperparâmetros:\n","\n","- **n_estimators**: quanto maior o número de estimadores, mais e com menos viés será aprendido dos dados\n","- **max_features**: uma quantidade menor de *features* pode ajudar o modelo a remover correlações enviesadas\n","- **max_depth**: profundidades maiores aumentam a chance de *overfitting*, mas dão mais ganho de informação ao modelo\n","- **min_samples_split**: um número mínimo de observações maior pode reduzir o *overfitting*\n","\n","Todos os hiperparâmetros estão inicialmente nos seus valores padrão.\n","\n","Rode a célula abaixo e clique em **Run Interact** para testar quantas vezes você quiser!"]},{"cell_type":"code","metadata":{"id":"N1x-dEiYbKnx","scrolled":false},"source":["##### Random Forest 2\n","\n","from IPython.display import display\n","from ipywidgets import interact_manual\n","import ipywidgets as widgets\n","\n","def teste_treino(nEstimators, maxFeatures, maxDepth, minSamplesSplit):\n","    \n","    # criando o objeto do modelo com RandomForestRegressor\n","    rf_model_2 = RandomForestRegressor(n_estimators = nEstimators,\n","                                    max_features = maxFeatures, \n","                                    max_depth = maxDepth, \n","                                    min_samples_split = minSamplesSplit,\n","                                    random_state = seed)\n","\n","    # treinando o modelo com os dados de treino\n","    rf_model_2.fit(X_train, y_train)\n","\n","    # prevendo com o modelo nos dados de validação\n","    y_pred = rf_model_2.predict(X_val)\n","\n","    # calculando e imprimindo algumas métricas\n","    \n","    print(\"Score on training set: {:.3f}\".format(rf_model_2.score(X_train, y_train)))\n","    print(\"Score on validation set: {:.3f}\".format(rf_model_2.score(X_val, y_val)))\n","    y = [rf_model_2.score(X_train, y_train), \n","         rf_model_2.score(X_val, y_val)]\n","    x = [\"Train Score\", \"Test Score\"]\n","    width = 1/2\n","    plt.bar(x, y, width, color=\"blue\")  \n","    print(\"Explained variance score: {:.3f}\".format(explained_variance_score(y_val, y_pred)))\n","    print(\"Mean absolute error (MAE): {:.3f}\".format(mean_absolute_error(y_val, y_pred)))\n","    print(\"Mean squared error (MSE): {:.3f}\".format(mean_squared_error(y_val, y_pred)))\n","    print(\"Mean squared log error (MSLE): {:.3f}\".format(mean_squared_log_error(y_val, y_pred)))\n","    print(\"R² Score: {:.3f}\".format(r2_score(y_val, y_pred)))\n","    \n","# essas são as linhas de código para criar os seletores\n","_ = interact_manual(teste_treino, \n","                    nEstimators =     widgets.IntSlider(min = 5, max = 1000, step = 1, value = 100),\n","                    maxFeatures =     widgets.IntSlider(min = 2, max = 13, step = 1, value = 13),\n","                    maxDepth =        widgets.IntSlider(min = 2, max = 100, step = 1, value = 50),\n","                    minSamplesSplit = widgets.IntSlider(min = 2, max = 30, step = 1, value = 2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Ad_Tua8bKn2"},"source":["É interessante notar que diminuir o número de *features* aumenta o R² nos dados de validação. Isso ocorre pelo fato de que, com menos *features* de cada vez em uma árvore, o modelo pode observar comportamentos diferentes, o que reduz o *overfitting*.\n","\n","Agora vamos usar a validação cruzada com a *random forest*. A principal diferença em relação ao que fizemos antes é que vamos usar a função ```GridSearchCV``` que serve para *grid search* mas também para a validação cruzada. No caso, não utilizaremos o *grid*."]},{"cell_type":"code","metadata":{"id":"ooJlK4NWbKn3","scrolled":false},"source":["# Random Forest com validação cruzada\n","\n","# importando a função de grid search do sklearn\n","from sklearn.model_selection import GridSearchCV\n","import pandas as pd\n","\n","# definindo os valores possíveis dos parâmetros a serem testados\n","params = {}\n","\n","# criando o objeto do modelo com RandomForestRegressor\n","rf_model_cv = RandomForestRegressor(random_state = seed)\n","\n","# criando o objeto do grid search com GridSearchCV\n","grid_search = GridSearchCV(rf_model_cv, param_grid = params, return_train_score=True) # valor padrão para quebras é 3\n","\n","# treinando o modelo com o grid search\n","grid_search.fit(X_training, y_training)\n","\n","# pegando os resultados da validação cruzada (cv_results)\n","cv_results = pd.DataFrame(grid_search.cv_results_)\n","\n","# imprimindo o score médio nas bases de treino\n","print(\"Average Score on train set: {:.3f} +/- {:.3f}\".format(cv_results[cv_results.rank_test_score == 1].mean_train_score.values[0],\n","                                                                     cv_results[cv_results.rank_test_score == 1].std_train_score.values[0]))\n","# imprimindo o score médio nas bases de validação\n","print(\"Average Score on validation set: {:.3f} +/- {:.3f}\".format(cv_results[cv_results.rank_test_score == 1].mean_test_score.values[0],\n","                                                                     cv_results[cv_results.rank_test_score == 1].std_test_score.values[0]))\n","\n","y = [cv_results[cv_results.rank_test_score == 1].mean_train_score.values[0], \n","     cv_results[cv_results.rank_test_score == 1].mean_test_score.values[0]]\n","x = [\"Train Score\", \"Validation Score\"]\n","width = 1/2\n","plt.bar(x, y, width, color=\"blue\")  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kwMhfP7rbKn7"},"source":["Como podemos ver, utilizamos os mesmos parâmetros padrões que haviamos usado no primeiro modelo de *random forest*, mas o R² de validação foi maior. Isso ocorreu devido à validação cruzada.\n","\n","Agora, vamos fazer o *grid search*. Essa técnica consiste em definir um conjunto de valores que determinado hiperparâmetro pode ter e treinar um modelo para cada combinação desses hiperparâmetros, e então selecionar a combinação com o melhor resultado.\n","\n","Para fazer isso, vamos definir um dicionário com os valores dos hiperparâmetros a serem testados e usar ```GridSearchCV```para treinar todos os modelos, passando os valores possíveis, a métrica de avaliação e as quebras de validação cruzada. Assim, pegaremos o atributo ```best_params_```para treinar o modelo final.\n","\n","Além disso, dessa vez faremos o gráfico de importância de variáveis para o melhor modelo. Esse gráfico mostra quais foram as variáveis mais importantes para o modelo.\n","\n","Atenção: isso pode levar algum tempo."]},{"cell_type":"code","metadata":{"id":"P2eXU3j_bKn7"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Random Forest com validação cruzada e Grid Search\n","\n","# definindo os valores possíveis dos parâmetros a serem testados\n","params = {'n_estimators': [5, 50, 100, 500],\n","          'max_features': [2, 5, 9, 13],\n","          'max_depth': [2, 5, 10, 50],\n","          'min_samples_split': [2, 8, 15, 30],}\n","\n","# criando o objeto do modelo com RandomForestRegressor\n","rf_model_cv_gs = RandomForestRegressor(random_state = seed)\n","\n","# criando o objeto do grid search com GridSearchCV\n","grid_search = GridSearchCV(rf_model_cv_gs, param_grid=params, return_train_score=True) # valor padrão para quebras é 3\n","\n","# treinando o modelo com o grid search\n","grid_search.fit(X_training, y_training)\n","\n","# imprimindo a melhor combinação de hiperparâmetros\n","print('\\n Best hyperparameters:')\n","print(grid_search.best_params_)\n","\n","# pegando os resultados da validação cruzada (cv_results)\n","cv_results = pd.DataFrame(grid_search.cv_results_)\n","\n","# imprimindo o score médio nas bases de treino\n","print(\"Average Score on train set: {:.3f} +/- {:.3f}\".format(cv_results[cv_results.rank_test_score == 1].mean_train_score.values[0],\n","                                                                     cv_results[cv_results.rank_test_score == 1].std_train_score.values[0]))\n","# imprimindo o score médio nas bases de validação\n","print(\"Average Score on validation set: {:.3f} +/- {:.3f}\".format(cv_results[cv_results.rank_test_score == 1].mean_test_score.values[0],\n","                                                                     cv_results[cv_results.rank_test_score == 1].std_test_score.values[0])) \n","\n","# configurando o modelo com a melhor combinação de hiperparâmetros\n","rf_model_cv_gs.set_params(n_estimators = grid_search.best_params_['n_estimators'],\n","                           max_features = grid_search.best_params_['max_features'],\n","                           max_depth = grid_search.best_params_['max_depth'],\n","                           min_samples_split = grid_search.best_params_['min_samples_split'])\n","\n","# treinando um modelo com a melhor combinação de hiperparâmetros\n","rf_model_cv_gs.fit(X_training, y_training)\n","\n","features = estate_df['feature_names']\n","importances = rf_model_cv_gs.feature_importances_\n","indices = np.argsort(importances)\n","\n","plt.title('Feature Importances')\n","plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n","plt.yticks(range(len(indices)), [features[i] for i in indices])\n","plt.xlabel('Relative Importance')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"We1moJwubKoA"},"source":["Podemos ver que usando o *Grid Search* os melhores parâmetros selecionados foram ```max_depth```de 50, ```max_features```de 5 e um número de estimadores de 100. O R² na base de validação subiu 0,02, ficando maior que nas nossas tentativas anteriores.\n","\n","As variáveis mais importantes foram **LSTAT** e **RM**, que são o percentual de baixa renda na população e a média de quartos por habitação. Será que esses resultados fazem sentido?"]},{"cell_type":"code","metadata":{"id":"87ulXUZzbKoB"},"source":["# Desenhando o gráfico de valores previstos por valores reais\n","y_pred = rf_model_cv_gs.predict(X_val)\n","plt.figure(figsize=(16,8))\n","plt.title('Boston House Prices - Predicted vs Real',fontsize=20)\n","df = pd.DataFrame({'real':y_val,'RF':rf_model_cv_gs.predict(X_val)})\n","df.sort_values(by=['real'],ascending=True,inplace=True)\n","df = df.reset_index(drop=True)\n","plt.plot(df)\n","plt.legend(['Real price','RF Predicted price'],fontsize=20)\n","plt.ylabel('$ Price',fontsize=20)\n","plt.xlabel('Observations ordered by price',fontsize=20)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vg5KGTG5bKoG"},"source":["### 5.2. Light GBM"]},{"cell_type":"markdown","metadata":{"id":"ell_AsFEbKoI"},"source":["#### 5.2.1. Teoria\n","*Light GBM*, ou *Light Gradient Boosting Machine*, é um modelo de *ensemble*, como o *Extreme Gradient Boosting* presente na aula de classificação. A principal diferença entre o *Light GBM* e a maioria dos outros métodos de *boosting* é que ele usa um mecanismo diferente para a criação das árvores, que é mais rápido.\n","\n","A maioria dos métodos de *boosting* funcionam da seguinte forma:\n","\n","<img src = https://cdn-images-1.medium.com/max/800/1*whSa8rY4sgFQj1rEcWr8Ag.png width=600>\n","\n","Enquanto o *Light GMB* funciona mais parecido com essa forma:\n","\n","<img src = https://cdn-images-1.medium.com/max/1600/1*AZsSoXb8lc5N6mnhqX5JCg.png width=600>\n","\n","Então podemos dizer que o *Light GBM* cria suas árvores **verticalmente**, enquanto outros algoritmos as criam **horizontalmente**. Em outras palavras, o *Light GBM* cresce suas árvores por folha, enquanto os demais crescem suas árvores por níveis. Assim, ele decide a quebra a ser feita na árvore pela folha que terá o maior ganho de informação.\n","\n","Para mais detalhes de como o *Light GBM* funciona, veja [aqui](https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc) para um artigo do Medium e [aqui](https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db) para um artigo do Towards Data Science que compara diferentes algoritmos de *boosting*.\n","\n","Além disso, [esse vídeo](https://www.youtube.com/watch?v=5CWwwtEM2TA) (a partir dos 10 minutos) explica um pouco mais a teoria por trás do *Light GBM*.\n","\n","Adicionalmente, veja [essa página](https://lightgbm.readthedocs.io/en/latest/Experiments.html) que mostra alguns experimentos comparando o *XGBoost* e o *LightGBM* em termos de velocidade, acurácia e uso de memória. Os resultados são surpreendentes!"]},{"cell_type":"markdown","metadata":{"id":"irercUn2bKoK"},"source":["#### 5.2.2. Código em Python e Avaliação\n","\n","A primeira coisa que precisamos fazer é instalar o pacote do Light GBM."]},{"cell_type":"code","metadata":{"id":"L5ccQzotbKoK","scrolled":false},"source":["import sys\n","!{sys.executable} -m pip install lightgbm"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YckLKDhTbKoN"},"source":["Agora importamos tudo o que precisamos. O mais importante é o ```Light GBM```, que chamaremos de **lgb**. Seria necessário também importar as métricas de avaliação dos modelos, mas já fizemos isso no caso do *random forest*."]},{"cell_type":"code","metadata":{"id":"6q_4M-sdbKoO"},"source":["import lightgbm as lgb"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ucdy-I77bKoU"},"source":["Agora vamos treinar nosso primeiro modelo de *Light GBM*. Podemos começar?\n","\n","Esse passo é bem parecido com o do *random forest*. Basicamente, é: criar o objeto do modelo de random forest com seus hiperparâmetros. Já que estamos com um problema de regressão, vamos usar a classe ```LGBMRegressor```. Você consegue ver os parâmetros disponíveis para criar esse objeto [aqui](https://lightgbm.readthedocs.io/en/latest/Parameters.html). Já que existem centenas de parâmetros para o *Light GBM*, há uma lista das implicações da maioria dos parâmetros [aqui](https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html).\n","\n","Os principais parâmetros que vamos usar nessa aula são:\n","- **task \\[padrão = train\\]**: use 'train' para treinar o modelo e 'predict' para aplicá-lo em uma nova base\n","- **objective \\[padrão = regression\\]**: define o tipo de problema e a função objetivo a ser utilizada\n","- **num_leaves \\[padrão = 31\\]**: número máximo de folhas em uma árvore\n","- **min_data_in_leaf \\[padrão = 20\\]**: quantidade mínima de dados em cada folha. Pode ser utilizado para lidar com o *over-fitting*, já que caso haja pouco dado em uma folha, as chances daquele comportamento só existir na base de treino são maiores\n","- **max_depth \\[padrão = -1\\]**: < 0 significa sem limite. Limita a profundidade máxima do modelo. Isso é útil para lidar com o *over-fitting* quando o dado é pequeno. A árvore continua sendo criada por folhas\n","- **max_bin \\[padrão = 255\\]**: número máximo de classes em que os valores das *features* serão agrupados. Um número pequeno de classes pode reduzir a acurácia de treino, mas lidar melhor com o *over-fitting*\n","- **min_gain_to_split \\[padrão = 0.0\\]**: o ganho de informação mínimo para fazer uma quebra na árvore\n","- **learning_rate \\[padrão = 0.1\\]**: taxa de aprendizagem, quanto menor, melhor para a acurácia\n","- **num_iterations \\[padrão = 100\\]**: número de iterações do *boosting*, quanto maior, maior as chances de convergencia\n","- **metric \\[padrão = \"\", changes according to objective\\]**: define a métrica de avaliação do treino\n","\n","Como feito com o *random forest*, iniciaremos com os hiperparâmetros padrões no nosso primeiro modelo."]},{"cell_type":"code","metadata":{"id":"Ked13GxfbKoU"},"source":["##### LightGBM 1\n","# criando o objeto do modelo com LGBMRegressor\n","lgb_model_1 = lgb.LGBMRegressor(random_state = seed)\n","\n","# treinando o modelo com os dados de treino\n","lgb_model_1.fit(X_train, y_train)\n","\n","# prevendo com o modelo nos dados de validação\n","y_pred = lgb_model_1.predict(X_val)\n","\n","# calculando e imprimindo algumas métricas\n","print(\"Score on training set: {:.3f}\".format(lgb_model_1.score(X_train, y_train)))\n","print(\"Score on validation set: {:.3f}\".format(lgb_model_1.score(X_val, y_val)))\n","y = [lgb_model_1.score(X_train, y_train), \n","     lgb_model_1.score(X_val, y_val)]\n","x = [\"Train Score\", \"Test Score\"]\n","width = 1/2\n","plt.bar(x, y, width, color=\"blue\") \n","print(\"Explained variance score: {:.3f}\".format(explained_variance_score(y_val, y_pred)))\n","print(\"Mean absolute error (MAE): {:.3f}\".format(mean_absolute_error(y_val, y_pred)))\n","print(\"Mean squared error (MSE): {:.3f}\".format(mean_squared_error(y_val, y_pred)))\n","print(\"Mean squared log error (MSLE): {:.3f}\".format(mean_squared_log_error(y_val, y_pred)))\n","print(\"R² Score: {:.3f}\".format(r2_score(y_val, y_pred)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2q6HTaf5bKoZ"},"source":["Como podemos ver, o modelo treinado tem um R² de 96,6% nos dados de treinos e 73,1% nos dados de validação, representando uma diferença de 23,5% entre eles.\n","\n","Mais uma vez obtivemos R²s bem diferentes nos dados de treino e validação com os hiperparâmetros padrões, indicando um *over-fitting*. Então vamos mexer um pouco com eles para tentar melhorar isso.\n","\n","Relembrando algumas características dos hiperparâmetros:\n","\n","- **max_depth**: valores maiores vai deixar as árvores mais profundas, tendo mais folhas e, consequentemente, com mais chance de *over-fitting*\n","- **learning_rate**: a taxa na qual o modelo vai aprender novas informações a cada iteração. Valores menores fazem o modelo ser mais demorado, mas melhor. Valores maiores trará mais ganho de informação mais rapidamente, mas com mais chance de *over-fitting*\n","- **num_leaves**: quanto maior esse número, mais o modelo tentará aprender sobre os dados de treino. Tentar aprender demais poderá causar *over-fitting*. Adicionalmente, quanto menor o *learning_rate*, maior deve ser o *num_leaves* para o mesmo grau de aprendizagem\n","- **min_data_in_leaf**: aumentar esse número vai restringir mais a quebra das folhas\n","- **min_gain_to_split**: similar à métrica acima mas calculado pelo ganho de informação\n","\n","Mais uma vez, todos os parâmetros estão inicialmente nos seus valores padrão, use o botão **Run Interact** para testar quantas vezes quiser!"]},{"cell_type":"code","metadata":{"id":"_KaqwZPQbKoZ","scrolled":false},"source":["##### LightGBM 2\n","\n","from IPython.display import display\n","from ipywidgets import interact_manual, IntSlider, FloatSlider\n","def teste_treino(maxDepth, learningRate, numIterations, numLeaves, minDataInLeaf, minGainToSplit):\n","    \n","    # criando o objeto do modelo com LGBMRegressor\n","    lgb_model_2 = lgb.LGBMRegressor(max_depth = maxDepth,\n","                                    learning_rate = learningRate, \n","                                    num_iterations = numIterations, \n","                                    num_leaves = numLeaves,\n","                                    min_data_in_leaf = minDataInLeaf,\n","                                    min_gain_to_split = minGainToSplit,\n","                                    random_state = seed)\n","\n","    # treinando o modelo com os dados de treino\n","    lgb_model_2.fit(X_train, y_train)\n","\n","    # prevendo com o modelo nos dados de validação\n","    y_pred = lgb_model_2.predict(X_val)\n","\n","    # calculando e imprimindo algumas métricas\n","    \n","    print(\"Score on training set: {:.3f}\".format(lgb_model_2.score(X_train, y_train)))\n","    print(\"Score on validation set: {:.3f}\".format(lgb_model_2.score(X_val, y_val)))\n","    y = [lgb_model_2.score(X_train, y_train), \n","         lgb_model_2.score(X_val, y_val)]\n","    x = [\"Train Score\", \"Test Score\"]\n","    width = 1/2\n","    plt.bar(x, y, width, color=\"blue\")  \n","    print(\"Explained variance score: {:.3f}\".format(explained_variance_score(y_val, y_pred)))\n","    print(\"Mean absolute error (MAE): {:.3f}\".format(mean_absolute_error(y_val, y_pred)))\n","    print(\"Mean squared error (MSE): {:.3f}\".format(mean_squared_error(y_val, y_pred)))\n","    print(\"Mean squared log error (MSLE): {:.3f}\".format(mean_squared_log_error(y_val, y_pred)))\n","    print(\"R² Score: {:.3f}\".format(r2_score(y_val, y_pred)))\n","    \n","# essas são as linhas de código para criar os seletores\n","_ = interact_manual(teste_treino, \n","             maxDepth =       IntSlider(min = 2, max = 50, step = 1, value = 20),\n","             learningRate =   FloatSlider(min = 0.001, max = 0.3, step = 0.001, value = 0.1),\n","             numIterations =  IntSlider(min = 20, max = 600, step = 20, value = 100),\n","             numLeaves =      IntSlider(min = 20, max = 300, step = 20, value = 100),\n","             minDataInLeaf =  IntSlider(min = 2, max = 50, step = 1, value = 20),\n","             minGainToSplit = FloatSlider(min =0., max = 30, step = 1., value = 0.0))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YyO5I4InbKoc"},"source":["Tente abaixar o *learning_rate* para 0,05, aumentar o número de iterações para 300 e reduzir a quantidade mínima em cada folha. Isso deve melhorar o R² da base de validação ainda mais, o que significa que estaríamos diminuindo o *over-fitting*.\n","\n","Agora vamos utilizar a validação cruzada com o *Light GBM*. O processo é bastante parecido com o feito com o *random forest*."]},{"cell_type":"code","metadata":{"id":"3eVlvL8VbKod"},"source":["# Light GBM com validação cruzada\n","\n","# importando a função de grid search do sklearn\n","from sklearn.model_selection import GridSearchCV\n","\n","# definindo os valores possíveis dos parâmetros a serem testados\n","params = {}\n","\n","# criando o objeto do modelo com XGBClassifier\n","lgb_model_cv = lgb.LGBMRegressor(random_state = seed)\n","\n","# criando o objeto do grid search com GridSearchCV\n","grid_search = GridSearchCV(lgb_model_cv, param_grid=params, return_train_score=True) #default value for splitting is 3\n","\n","# treinando o modelo com o grid search\n","grid_search.fit(X_training, y_training)\n","\n","# pegando os resultados da validação cruzada (cv_results)\n","cv_results = pd.DataFrame(grid_search.cv_results_)\n","\n","# imprimindo o score médio nas bases de treino\n","print(\"Average Score on validation set: {:.3f} +/- {:.3f}\".format(cv_results[cv_results.rank_test_score == 1].mean_train_score.values[0],\n","                                                                     cv_results[cv_results.rank_test_score == 1].std_train_score.values[0]))\n","\n","# imprimindo o score médio nas bases de validação\n","print(\"Average Score on validation set: {:.3f} +/- {:.3f}\".format(cv_results[cv_results.rank_test_score == 1].mean_test_score.values[0],\n","                                                                     cv_results[cv_results.rank_test_score == 1].std_test_score.values[0]))\n","\n","y = [cv_results[cv_results.rank_test_score == 1].mean_train_score.values[0], \n","     cv_results[cv_results.rank_test_score == 1].mean_test_score.values[0]]\n","x = [\"Train Score\", \"Test Score\"]\n","width = 1/2\n","plt.bar(x, y, width, color=\"blue\")  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rb1GpoYIbKoh"},"source":["Mais uma vez, pudemos ver um crescimento no R² de validação ao utilizar a validação cruzada, assim como verificamos com o *random forest*.\n","\n","Agora vamos utilizar o *grid search* com o *Light GBM*, de forma muito parecida com o que fizemos para o *random forest*.\n","\n","Atenção: isso pode levar algum tempo."]},{"cell_type":"code","metadata":{"id":"K0e0C8RWbKoi"},"source":["# Light GBM com validação cruzada e Grid Search\n","\n","# definindo os valores possíveis dos parâmetros a serem testados\n","params = {'max_depth': [2, 5, 10, 50],\n","          'learning_rate': [0.01, 0.03, 0.1, 0.5],\n","          'num_iterations': [50, 100, 200, 500],\n","          'min_data_in_leaf': [5, 20, 50],\n","          'min_gain_to_split': [0., 0.5, 1, 5]}\n","\n","# criando o objeto do modelo com XGBClassifier\n","lgb_model_cv_gs = lgb.LGBMRegressor(random_state = seed)\n","\n","# criando o objeto do grid search com GridSearchCV\n","grid_search = GridSearchCV(lgb_model_cv_gs, param_grid=params, return_train_score=True) #default value for splitting is 3\n","\n","# treinando o modelo com o grid search\n","grid_search.fit(X_training, y_training)\n","\n","# # imprimindo a melhor combinação de hiperparâmetros\n","print('\\n Best hyperparameters:')\n","print(grid_search.best_params_)\n","\n","# pegando os resultados da validação cruzada (cv_results)\n","cv_results = pd.DataFrame(grid_search.cv_results_)\n","\n","# imprimindo o score médio nas bases de treino\n","print(\"Average Score on validation set: {:.3f} +/- {:.3f}\".format(cv_results[cv_results.rank_test_score == 1].mean_train_score.values[0],\n","                                                                     cv_results[cv_results.rank_test_score == 1].std_train_score.values[0]))\n","\n","# imprimindo o score médio nas bases de validação\n","print(\"Average Score on validation set: {:.3f} +/- {:.3f}\".format(cv_results[cv_results.rank_test_score == 1].mean_test_score.values[0],\n","                                                                     cv_results[cv_results.rank_test_score == 1].std_test_score.values[0]))\n","\n","# configurando o modelo com a melhor combinação de hiperparâmetros\n","lgb_model_cv_gs.set_params(max_depth = grid_search.best_params_['max_depth'],\n","                           learning_rate = grid_search.best_params_['learning_rate'],\n","                           min_data_in_leaf = grid_search.best_params_['min_data_in_leaf'],\n","                           min_gain_to_split = grid_search.best_params_['min_gain_to_split'])\n","\n","# treinando um modelo com a melhor combinação de hiperparâmetros\n","lgb_model_cv_gs.fit(X_training, y_training)\n","\n","# desenhando o gráfico de impoartância de variáveis\n","features = estate_df['feature_names']\n","importances = lgb_model_cv_gs.feature_importances_\n","indices = np.argsort(importances)\n","\n","plt.title('Feature Importances')\n","plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n","plt.yticks(range(len(indices)), [features[i] for i in indices])\n","plt.xlabel('Relative Importance')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R3YaFYMKbKop"},"source":["# Desenhando o gráfico de valores previstos por valores reais\n","y_pred = lgb_model_cv_gs.predict(X_val)\n","plt.figure(figsize=(16,8))\n","plt.title('Boston House Prices - Predicted vs Real',fontsize=20)\n","df = pd.DataFrame({'real':y_val,'LGBM':lgb_model_cv_gs.predict(X_val)})\n","df.sort_values(by=['real'],ascending=True,inplace=True)\n","df = df.reset_index(drop=True)\n","plt.plot(df)\n","plt.legend(['Real price','LGBM Predicted price'],fontsize=20)\n","plt.ylabel('$ Price',fontsize=20)\n","plt.xlabel('Observations ordered by price',fontsize=20)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H9oljnkIbKos"},"source":["O *grid search* selecionou o ```max_depth``` de 2, o ```min_data_in_leaf``` de 5 e o número de iterações de 500 na melhor iteração. O R² de validação aumentou para 0,871, melhor do que nas nossas tentativas anteriores!\n","\n","Dessa vez, as variáveis mais importantes foram **LSTAT** and **DIS**, que são o percentual de baixa renda na população e a distância média da casa para o centros empresariais de Boston. E dessa vez, isso faz sentido?"]},{"cell_type":"markdown","metadata":{"id":"jAD9U89h1o4S"},"source":["### 5.3. Redes Neurais"]},{"cell_type":"markdown","metadata":{"id":"Xs30EEP-1ri7"},"source":["#### 5.3.1. Teoria\n","Diferentemente dos métodos anteriores, as redes neurais são inspiradas por estruturas biológicas. Como o próprio nome diz, esse método tenta criar uma rede de neurônios. Nosso cérebro é talvez a máquina mais poderosa que existe e contém uma rede muito grande de neurônios interconectados para que seja capaz de processar informações. Em resumo, a principal função dos neurônios é coletar as entradas de outros neurônios pelos dendritos. Cada neurônio soma todas suas entredas e, se o resultado for maior que um limiar, ele ativa. Essa ativação então libera um sinal pro próximo neurônio.\n","\n","Legal, não?! Mas como será que isso funciona como uma técnica de _Machine Learning_?\n","\n","Bom que você perguntou... rs. Em uma rede neural, o neurônio nada mais é do que um nome chique pra uma função. Então, ele basicamente recebe um conjunto de entrada, aplica alguma lógica, e dá o resultado na saída.\n","\n","E, assim, uma rede neural é uma rede de funções! Uma rede neural simples se parece com essa a seguir:\n","\n","![Imgur](https://upload.wikimedia.org/wikipedia/commons/1/1d/Neural_network_example.png)\n","\n","Como dá para ver na imagem acima, a rede neural é construída com 3 tipos de camadas:\n","1. Camada de entrada (input layer): recebe os dados iniciais da rede neural\n","2. Camadas escondidas (hidden leayers): camadas intermediárias entre as entradas e as saídas onde todo cálculo é feito\n","3. Camada de saída (output layer): produz os resultados para as entradas dadas\n","\n","Cada nó é conectado com todos os nós da camada seguinte e cada conexão (setas pretas) tem um peso associado. Esse peso pode ser entendido como o impacto que aquele nó tem no nó da próxima camada.\n","\n","Essa é uma breve introdução da ideia da rede neural. Para melhor entendimento do funcionamento das redes, sugerimos as fontes a seguir:\n","1. [Neural Networks Explained](https://www.youtube.com/watch?v=GvQwE2OhL8I&feature=youtu.be): vídeo de 12 minutos, mas que dá uma boa explicação sobre os conceitos básicos.\n","2. [But what *is* a Neural Network?](https://www.youtube.com/watch?v=aircAruvnKk&feature=youtu.be): vídeo de 20 minutos, mas dá uma explicação boa e intuitiva, usando o problema de reconhecimento de números.\n","3. [Artigo do Medium](https://medium.com/technologymadeeasy/for-dummies-the-introduction-to-neural-networks-we-all-need-c50f6012d5eb)\n","4. [Using neural networks to recognized handwritting digits](http://neuralnetworksanddeeplearning.com/chap1.html)\n","5. [Ferramenta de redes neurais](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4&seed=0.66497&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=true&xSquared=true&ySquared=true&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)\n","6. [Artigo do Towards data science](https://towardsdatascience.com/everything-you-need-to-know-about-neural-networks-and-backpropagation-machine-learning-made-easy-e5285bc2be3a)"]},{"cell_type":"markdown","metadata":{"id":"tTU2RTJS1w3S"},"source":["#### 5.3.2. Código em Python e Avaliação\n","\n","Para construir um regressor usando uma rede neural, a primeira coisa que temos que fazer é importar ```MLPRegressor```da biblioteca ```sklearn```."]},{"cell_type":"code","metadata":{"id":"_0ar_6b51zD4"},"source":["from sklearn.neural_network import MLPRegressor"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EIV8qeqY1zqM"},"source":["Antes de fazermos de fato a nossa primeira rede neural, vamos ver quais são os principais atributos que temos para configurá-la.\n","- <i>hidden_layer_sizes</i>: uma tupla, no qual o nº elemento representa o número de neurônios na nª camada escondida\n","- <i>activation</i>: representa a função de ativação utilizada na camada escondida. Pode ser 'identity', 'logistic', 'tanh' ou 'relu'.\n","- <i>solver</i>: o algoritmo de solução para a otimização dos pesos. Para _datasets_ pequenos 'lbfgs' converge mais rapidamente e tem bons resultados, enquanto 'adam' funciona melhor em dados relativamente grandes\n","\n","Se quiser entender melhor os demais hiperparâmetros, veja nesse [link](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html)\n","\n","Dado que as redes neurais exploram as relações matemáticas entre as variáveis, a qualidade do nosso modelo pode ser afetada pelo fato das _features_ terem ordens de magnitudes diferentes. Imagine, por exemplo, um modelo que faz a soma de duas variáveis em uma camada: se uma delas for em média muito maior que a outra, ela automaticamente terá um peso maior no processo.\n","\n","Por isso, é importante normalizar as variáveis com um _scaler_:"]},{"cell_type":"code","metadata":{"id":"3Xy3DyJV13_S"},"source":["from sklearn.preprocessing import StandardScaler\n","\n","sc = StandardScaler()\n","X_train_scaled = sc.fit_transform(X_train)\n","X_val_scaled = sc.transform(X_val)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Qsv60o916iC"},"source":["# criando o objeto do modelo com MLPRegressor\n","neural_network_model = MLPRegressor(activation='tanh', \n","                                    solver = 'lbfgs',\n","                                    hidden_layer_sizes=(2),\n","                                    early_stopping = True)\n","\n","# treinando o modelo com os dados de treino\n","neural_network_model.fit(X_train_scaled, y_train)\n","\n","# prever com o modelo nos dados de validacao\n","y_pred = neural_network_model.predict(X_val_scaled)\n","\n","# calculando e imprimindo algumas métricas\n","print(\"Score on training set: {:.3f}\".format(neural_network_model.score(X_train_scaled, y_train)))\n","print(\"Score on validation set: {:.3f}\".format(neural_network_model.score(X_val_scaled, y_val)))\n","y = [neural_network_model.score(X_train_scaled, y_train), \n","     neural_network_model.score(X_val_scaled, y_val)]\n","x = [\"Train Score\", \"Validation Score\"]\n","width = 1/2\n","plt.bar(x, y, width, color=\"blue\") \n","print(\"Explained variance score: {:.3f}\".format(explained_variance_score(y_val, y_pred)))\n","print(\"Mean absolute error (MAE): {:.3f}\".format(mean_absolute_error(y_val, y_pred)))\n","print(\"Mean squared error (MSE): {:.3f}\".format(mean_squared_error(y_val, y_pred)))\n","print(\"Mean squared log error (MSLE): {:.3f}\".format(mean_squared_log_error(y_val, [x if x >= 0 else 0 for x in y_pred]))) # tratando valores negativos que podem ser previstos pela rede neural\n","print(\"R² Score: {:.3f}\".format(r2_score(y_val, y_pred)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sHs7zRkR18Q3"},"source":["# Desenhando o gráfico de valores previstos por valores reais\n","y_pred = neural_network_model.predict(X_val_scaled)\n","plt.figure(figsize=(16,8))\n","plt.title('Boston House Prices - Predicted vs Real',fontsize=20)\n","df = pd.DataFrame({'real':y_val,'NN':neural_network_model.predict(X_val_scaled)})\n","df.sort_values(by=['real'],ascending=True,inplace=True)\n","df = df.reset_index(drop=True)\n","plt.plot(df)\n","plt.legend(['Real price','Neural Network Predicted price'],fontsize=20)\n","plt.ylabel('$ Price',fontsize=20)\n","plt.xlabel('Observations ordered by price',fontsize=20)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S7Q0Jq971-F3"},"source":["Você pode tentar mudar o número de neurônios em cada camada e ver como isso altera o resultado.\n","\n","Não entraremos muito nos demais detalhes da teoria e da otimização das redes neurais."]},{"cell_type":"markdown","metadata":{"id":"-6sLLNb7bKo-"},"source":["### 5.4 Comparação entre os modelos"]},{"cell_type":"markdown","metadata":{"id":"KsFq84WobKo_"},"source":["Por fim, vamos desenhar todos os resultados no mesmo gráfico para tentarmos verificar qual modelo se adequa melhor aos dados reais."]},{"cell_type":"code","metadata":{"id":"c6gF4ph0bKo_"},"source":["# Desenhando o gráfico de valores previstos por valores reais para ambos os modelos\n","plt.figure(figsize=(16,10))\n","plt.title('Boston House Prices - Predicted vs Real',fontsize=20)\n","df = pd.DataFrame({'real':y_val,'Random Forest':rf_model_cv_gs.predict(X_val),'LGBM':lgb_model_cv_gs.predict(X_val),'NN':neural_network_model.predict(X_val_scaled)})\n","df.sort_values(by=['real'],ascending=True,inplace=True)\n","df = df.reset_index(drop=True)\n","plt.plot(df)\n","plt.legend(['Real price','Predicted RF price','Predicted LGBM price','Predicted NN price'],fontsize=20)\n","plt.ylabel('$ Price',fontsize=20)\n","plt.xlabel('Observations ordered by price',fontsize=20)\n","plt.show()\n","\n","plt.figure(figsize=(16,10))\n","plt.title('Boston House Prices - Predicted vs Real',fontsize=20)\n","plt.scatter(x=df['real'],y=df['Random Forest'],c='y')\n","plt.scatter(x=df['real'],y=df['LGBM'],c='g')\n","plt.scatter(x=df['real'],y=df['NN'],c='r')\n","plt.plot([0,50],[0,50],'k--')\n","plt.axis([0,51,0,51])\n","plt.legend(['Real price','Predicted RF price','Predicted LGBM price','Predicted NN price'],fontsize=20)\n","plt.xlabel('Real price',fontsize=20)\n","plt.ylabel('Predicted price',fontsize=20)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GIqrjDRQbKpD"},"source":["Pelos gráficos, parece que o nosso modelo mais simples (o *random forest*) se adequou melhor. Isso pode ocorrer devido ao fato da nossa base dedados ser relativamente pequena. Em geral, modelos mais complexos como os de *boosting* ou as redes neurais precisam de mais dados para não apresentarem *over-fitting*.\n","\n","O segundo gráfico nos dá outra visão da acurácia dos modelos. O *random forest* é visivelmente mais próximo da linha que representa os valores reais, o que significa que ele é melhor."]},{"cell_type":"markdown","metadata":{"id":"3gi3vv9TbKp4"},"source":["<a id=\"digdeeper\"></a>\n","## 6. Saiba mais\n","\n","* [Selecting the best ML algorithm for your regression problem](https://towardsdatascience.com/selecting-the-best-machine-learning-algorithm-for-your-regression-problem-20c330bad4ef)\n","* [Regression vs Classification](https://medium.com/quick-code/regression-versus-classification-machine-learning-whats-the-difference-345c56dd15f7)\n","* [XGBoost Algorithm: Long May She Reign!](https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d)"]}]}