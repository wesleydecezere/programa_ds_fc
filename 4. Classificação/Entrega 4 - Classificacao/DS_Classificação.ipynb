{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hN9TRGlsa-jg"
   },
   "source": [
    "# <center>Classificação</center>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M09Fg6BXa-ji"
   },
   "source": [
    "## Conteúdo\n",
    "1. [Recaptulação](#recap) <br>\n",
    "2. [Definição do Problema](#problem_def) <br>\n",
    "3. [Análise Inicial](#initial_analysis) <br>\n",
    "4. [Split Treino e Teste](#split) <br>\n",
    "5. [Modelagem](#modeling) <br>\n",
    "6. [Avaliação dos Modelos](#eval) <br>\n",
    "7. [Classificação Multiclasse](#multiclass) <br>\n",
    "[Dig Deeper](#digdeeper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAlCwOpFa-jl"
   },
   "source": [
    "<a id=\"recap\"></a>\n",
    "## 1. Recaptulação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6AmACPCa-jm"
   },
   "source": [
    "Nas aulas anteriores, discutimos o que é Aprendizado de Máquina e como ele pode ser utilizado para resolver diferentes problemas, dando uma visão geral das diferentes classes de algoritmos, quais problemas cada um trata e as principais métricas para avaliá-los.\n",
    "\n",
    "Nesta aula, focaremos em uma abordagem mais prática de como implementar e usar esses algoritimos em Python. Mais especificamente, exploraremos os principais algoritmos de classificação utilizados na indústria, como implementá-los usando a biblioteca ```scikit-learn```, como avaliá-los e selecionar o melhor para o problema em questão.\n",
    "\n",
    "> **Relembrando**: **Classificação** é uma técnica de aprendizado de máquina supervisionado que usa um conhecimento adquirido de dados de treino para classificar novas observações dentre um conjunto finito de possíveis classes. Embora hajam mais variações, a classificação é separada usalmente entre dois tipos distintos: classificação binária, cujo objetivo é identificar amostras em duas classes distintas, e classificação multiclasse, em que há duas ou mais classes mutualmente excludentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2iScVU1Ua-jn"
   },
   "source": [
    "<a id=\"problem_def\"></a>\n",
    "## 2. Definição do Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHEEa-kia-jo"
   },
   "source": [
    "Uma grande aplicação de técnicas de classificação é ajudar no diagnóstico médico. O [uso de aprendizado de máquina no prognóstico de câncer e previsão](https://www.sciencedirect.com/science/article/pii/S2001037014000464) está virando crucial para abordar esse problema, visto que permite iniciar o tratamento apropriado o mais cedo possível e consequentemente aumentar a chance de sobrevivência do paciente.\n",
    "\n",
    "Neste capítulo, vamos usar um dataset real incluso no ```scikit-learn```. O conjunto de dados público de câncer de mama de Wisconsin possui registros de medidas clínicas desses tumores. Eles são rotulados como tumores benignos e malignos e a tarefa consiste em aprender a **prever qual o seu tipo baseado nas medidas do tecido**.\n",
    "\n",
    "Nós vamos construir e avaliar alguns modelos para esta tarefa, que consiste em uma classificação binária (apenas duas classes). Note, entretanto, que as técnicas discutidas a seguir podem facilmente ser extendidas para outros problemas de classificação binária ou então multiclasse.\n",
    "\n",
    "Vamos começar importando o dataset e verificar sua descrição!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1040,
     "status": "ok",
     "timestamp": 1604405321563,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "WKYhrQ87a-jp",
    "outputId": "851c8fc2-966a-4473-cd1b-a0d162db8355"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "print(\"X\", X.shape)\n",
    "print(\"y\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87hgUFlga-jw"
   },
   "source": [
    "Datasets inclusos na biblioteca ```scikit-learn``` consistem em objetos *Bunch*, que contém os dados propriamente ditos mais diferentes informações adicionais sobre o conjunto de dados. Eles são similares a dicionários com o benefício adicional que você pode acessar seus valores usando uma sintaxe com pontos (dataset.label ao invés de dataset\\['label'\\]).\n",
    "\n",
    "Para ver todas as informações em um objeto *Bunch*, utilize o método ```.keys()```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDZENNOYa-jx",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Printar a descrição do dataset\n",
    "print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vtc_nw0Fa-j3"
   },
   "source": [
    "<a id=\"initial_analysis\"></a>\n",
    "## 3. Análise Inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maior parte dos conjuntos de dados disponíveis do ```scikit-learn``` são conhecidos como *toy datasets*, usados normalmente para propósitos educacionais e para realizar benchmarks de algoritmos. Portanto, eles geralmente possuem dados **limpos e tratados** para a modelagem. Porém, note que em qualquer problema ou conjunto de dados \"real\", as etapas de limpeza, preparação e engenharia de variáveis devem ser previamente realizadas.\n",
    "\n",
    "Antes de começar a construir o modelo, existem algumas análises importantes e mais sutis que devem ser consideradas. Abaixo algumas delas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Viés nos Dados\n",
    "As vezes, o processo de aquisição de dados pode estar sujeito a diferentes tipos de viéses. Algumas fontes comuns são:\n",
    "1. Medidas limitadas no tempo que não capturam a sazonalidade do fenômeno \n",
    "2. Restringir a pesquisa a grupos específicos, que não refletem o comportamento da população\n",
    "3. Relatar os dados em grupos categóricos enganosos\n",
    "\n",
    "Supondo que a presença de cancer é dependente da idade do indivíduo, uma preocupação pode ser: qual é a idade dos pacientes sujeitos ao diagnóstico? Eles pertencem ao mesmo grupo de indivíduos sob o qual o modelo final vai realizar previsões?\n",
    "\n",
    "Em geral, um bom entendimento dos seus dados e uma análise exploratória pode ajudar a entender e evitar a maior parte das fontes de viéses. As soluções adotadas podem variar de problema para problema e dependem do que você está tentando prever."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Balanceamento de Classe\n",
    "Infelizmente, em problemas de classificação, nem sempre as classes aparecem em amostras igualmente distribuídas. Se estamos tentando prever algo como fraudes, é esperado que tais casos sejam muito mais raros que os genuínos (não-fraudes). Isto é um problema, pois a maior parte dos algoritmos de Aprendizado de Máquina trabalha melhor quando o número de observações em cada classe é aproximadamente igual. Isto se deve ao impacto do desbalanceamento na função de perda/custo do modelo e sua métrica de avaliação. Clique na imagem do vídeo abaixo para uma explicação mais detalhada.\n",
    "\n",
    "[![img](http://img.youtube.com/vi/XeJZbCT84Js/0.jpg)](https://www.youtube.com/watch?v=XeJZbCT84Js)\n",
    "\n",
    "Portanto, nestes casos, é importante atentar-se à sua métrica de avaliação, usando o F1-Score ou AUC, por exemplo. Para obter um dataset mais balanceado, existem algumas técnicas possíveis como: subamostragem, ou undersampling (amostrar um de cada N pontos da classe majoritária para treino do modelo); sobreamostragem, ou oversampling (replicar as observações da classe minoritária); SMOTE (Synthetic Minority Oversampling Technique) em que pontos artificiais são criados no espaço dos atributos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Número de Features e Observações\n",
    "Para qualquer problema de aprendizado supervisionado, existe um certo limiar para a razão entre o número de features/variáveis e observações para que o modelo possa ter uma boa performance. Essa razão depende tanto da qualidade dos dados quanto do modelo usado.\n",
    "\n",
    "Caso esta condição não seja satisfeita, deve-se descartar algumas das variáveis usando algum tipo de técnica de seleção de features (feature selection), usar modelos que lidam bem com uma quantidade grande de features, ou simplesmente obter mais observações. Para o dataset de câncer de mama, a razão obervações/features é de aproximadamente 22 (o que é satisfatório para os modelos desenvolvidos aqui).\n",
    "\n",
    "Embora mais dados seja sempre melhor, as vezes não é possível ou não vale a pena obter mais. Além disso, ao invés de coletar e rotular os dados manualmente, existem plataformas como o [Amazon Mechanical Turk](https://www.mturk.com) ou técnicas como síntese de dados artificiais (artificial data synthesis) que podem ser úteis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAa4rhcza-j3"
   },
   "source": [
    "### 3.4. Sobreposição de Tempo e Vazamento de Dados\n",
    "Vazamento de dados é um grande problema ao construir modelos preditivos. Isto ocorre quando informação fora do dataset de treino é acidentalmente alimentado na fase de aprendizado (como a variável que está sendo prevista). Como os modelos de classificação são criados para fazer previsões sobre dados não vistos, não disponíveis ou futuros, deve-se garantir que estes não sejam fornecidos como entrada para as features do modelo no treino.\n",
    "\n",
    "Além disso, quando suas variáveis são dependentes no tempo, outro problema comum ocorre quando existe sobreposição. Isto é, o intervalo de tempo usado para calcular as features possui intersecção com o intervalo de tempo usado para calcular a variável resposta (target). Neste caso, o modelo não é causal, pois depende de informações sobre o futuro no momento da previsão.\n",
    "\n",
    "Uma evidência comum que pode indicar a existência de algum tipo de vazamento de dados ou sobreposição de tempo no modelo é o overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7-J277Sa-j4"
   },
   "source": [
    "#### Exercício 3.1\n",
    "\n",
    "As classes estão balanceadas no dataset? Use a célula abaixo para ajudá-lo a responder a questão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "exid": "3.1",
    "id": "DMp-wNxCa-j5"
   },
   "outputs": [],
   "source": [
    "#Avalie o percentual das classes 0 e 1 \n",
    "perc_0 = ___\n",
    "perc_1 = ___\n",
    "\n",
    "print(perc_0)\n",
    "print(perc_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKS2ntzza-j9"
   },
   "source": [
    "<a id=\"split\"></a>\n",
    "## 4. Split Treino-Validação-Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKWqZqgLa-j-"
   },
   "source": [
    "### 4.1. Train, validation and test sets\n",
    "\n",
    "Ao criar um modelo de aprendizado supervisionado, nosso objetivo é aprender padrões em dados históricos para que estes possam ser aplicados para prever dados futuros e não disponíveis no momento. O problema nisto é que se torna difícil avaliar o quão bom o modelo vai performar com dados indisponíveis.\n",
    "\n",
    "Desta forma, é necessário também usar os dados históricos para avaliar o modelo. Isto traz outro problema visto que é fácil para um modelo realizar previsões sobre dados já vistos no treino. Portanto, relembrando as discussões da primeira aula, é necessário separar os registros em diferentes grupos. São eles conjunto de treino, validação e teste.\n",
    "\n",
    "* **Conjunto de treino**: as amostras usadas para realizar o fit do modelo. Ele aprende os padrões destes dados e ajusta seus parâmetros de acordo.\n",
    "* **Conjunto de validação**: as amostras usadas para providenciar uma avaliação não enviesada de um modelo que foi treinado usando o conjunto de treino. A avaliação se torna enviesada à medida que as caracteristicas do dataset de validação é incorporado na configuração do modelo.\n",
    "* **Conjunto de teste**: as amostras usadas para providenciar uma avaliação não enviesada do modelo final treinado no dataset de treino. Também chamado de *holdout set*.\n",
    "\n",
    "O dataset de treino é de mais fácil compreensão. Mas por que usar conjuntos de validação e teste?\n",
    "\n",
    "A resposta se resume aos hiperparâmetros. Uma vez que cada algoritmo (k-NN, regressão logística, árvores de decisão, etc) possui vários deles, deve-se testar diferentes combinações de seus valores para obter o melhor modelo possível. Para fazer isso, treina-se modelos com diferentes combinações dos hiperparâmetros no conjunto de treino e então eles são avaliados no conjunto de validação, escolhendo a combinação que resulta na melhor métrica. Consequentemente, o modelo final fica enviesado pelos dados do conjunto de validação, mesmo que eles não tenham sido usados na fase de treino propriamente dita. Desta forma, faz-se necessário a separação de um terceiro conjunto de dados, o de teste, sob o qual o modelo deve ser novamente avaliado para que uma métrica não enviesada da performance do modelo possa ser estabelecida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6JFzme_a-j_"
   },
   "source": [
    "### 4.2. Validação Cruzada (Cross Validation)\n",
    "\n",
    "Uma questão que pode ser levantada é sobre a quantidade de observações a ser colocada em cada conjunto. O que ocorre caso deixemos uma parte importante dos dados fora do dataset de treino de forma que o modelo não aprenda padrões úteis? Para ajudar nisso, existe a chamada validação cruzada (cross validation).\n",
    "\n",
    "**Cross validation** é uma técnica de split de treino e validação que assegura que cada observação é usada tanto para o treino quanto para a validação. Existe mais de uma maneira de realizá-la que será descrita abaixo.\n",
    "\n",
    "Atenção: a validação cruzada trata apenas da separação entre os conjuntos de treino e validação e assume que já exista um conjunto isolado de observações o dataset de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCIK-mMh0uiy"
   },
   "source": [
    "#### 4.2.1. K-Folds\n",
    "O método K-Folds consiste em dividir todas as obsverções em $k$ grupos (folds) aleatórios, treinar o modelo em $k-1$ grupos, validar no $k$-ésimo grupo, repetir isto até que todos os grupos tenham sido utilizados como validação e, finalmente, calcular a média da métrica de avaliação sobre todos os $k$ modelos treinados. Isto corresponde à avaliação final do seu modelo.\n",
    "\n",
    "A imagem abaixo mostra um exemplo de uma validação cruzada com 10 grupos (folds). A métrica de avaliação, neste caso, a acurácia, é avaliada 10 vezes para cada grupo e então tirado a média.\n",
    "\n",
    "![kfold](https://qph.fs.quoracdn.net/main-qimg-29c6f21ce298acfa228f37448f844ab8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WiSYWe3g0yjg"
   },
   "source": [
    "#### 4.2.2. K-Folds Estratificado\n",
    "K-Folds estratificado é similar ao K-Folds, com a distinção de que cada grupo tem a mesma distribuição da variável resposta. Isto é importante para problemas de classificação, onde a proporção das classes não é sempre igual. Suponha, por exemplo, que o dataset possua uma classe minoritária. É possível que todas as observações dela se concentrem em apenas um grupo, tornando impossível o processo de aprendizado do modelo.\n",
    "\n",
    "A imagem abaixo ilustra melhor o processo.\n",
    "\n",
    "<img src=\"https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2015/11/skfold.png\" alt=\"stratifiedkfold\" style=\"width: 600px;\"/>\n",
    "\n",
    "Em resumo, o dataset de treino é utilizado para realizar o fit do modelo, o dataset de validação é utilizado para avaliar diferentes modelos com hiperparâmetros diferentes e selecionar o melhor, e o dataset de teste é usado para providenciar a métrica de avaliação final não enviesada.\n",
    "\n",
    "A imagem abaixo resume o processo.\n",
    "\n",
    "![sets](https://sebastianraschka.com/images/faq/evaluate-a-model/evaluate_overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DdApfy1ra-kA"
   },
   "source": [
    "### 4.3. Código em Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdipCyGSa-kB"
   },
   "source": [
    "#### 4.3.1. Split de Treino e Teste\n",
    "Primeiramente separamos o conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 918,
     "status": "ok",
     "timestamp": 1604405330292,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "8FtV4-yVa-kC",
    "outputId": "7243f994-4a3a-42b0-b747-28cb042c5eed"
   },
   "outputs": [],
   "source": [
    "# Importar train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Setar seed para obter resultados reproduziveis\n",
    "seed = 10\n",
    "\n",
    "# Usar train_test_split para criar o conjunto de teste\n",
    "# random_state é o estado inicial usado para geração de números aleatórios\n",
    "# test_size define o tamanho do conjunto de teste\n",
    "# stratify é usado para garantir a mesma proporção da variável resposta nos conjuntos\n",
    "X_training, X_test, y_training, y_test = train_test_split(X, y, random_state=seed, test_size=0.25, stratify=y)\n",
    "\n",
    "print(\"Test set X\", X_test.shape)\n",
    "print(\"Test set y\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCMQ_FOMa-kH"
   },
   "source": [
    "#### 4.3.2. Split de Treino e Validação\n",
    "Então dividimos as obsevações resultantes do treino para separar novamente no conjunto de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 672,
     "status": "ok",
     "timestamp": 1604405330699,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "6M97iIc3a-kI",
    "outputId": "1f20145d-91b6-485e-cf7b-26a4e446e93c"
   },
   "outputs": [],
   "source": [
    "# Mesmo procedimento, mas para o conjunto de trieno resultante\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_training, y_training, random_state=seed,\n",
    "                                                  test_size=0.33, stratify=y_training)\n",
    "\n",
    "print(\"Train set X\", X_train.shape)\n",
    "print(\"Train set y\", y_train.shape)\n",
    "print(\"Validation set X\", X_val.shape)\n",
    "print(\"Validation set y\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_g3mqVToa-kN"
   },
   "source": [
    "Usando a imagem abaixo como referência, em cada uma das variáveis, temos:\n",
    "\n",
    "- **X_test** e **y_test**: conjunto de teste (vermelho)\n",
    "- **X_training** e **y_training**: conjunto auxiliar de treino (verde superior) para o método de holdout (com validação cruzada)\n",
    "- **X_train** e **y_train**: conjunto de treino (verde inferior) para treino sem validação cruzada\n",
    "- **X_val** e **y_val**: conjunto de validação (amarelo) para avaliar os modelos sem validação cruzada\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1200/1*4G__SV580CxFj78o9yUXuQ.png\" alt=\"cv\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oR1BIzAWa-kO"
   },
   "source": [
    "<a id=\"modeling\"></a>\n",
    "## 5. Modelagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRvVVj6ya-kP"
   },
   "source": [
    "### 5.1. Árvores de Decisão (Decision Trees - DTs)\n",
    "Nesta subseção, vamos relembrar a teoria por trás das árvores de decisão e entrar um pouco mais em detalhes para entendermos seu funcionamento. Em seguida, utilizaremos este algoritmo da biblioteca ```scikit-learn``` para prever se o tumor é maligno ou não."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImK_Cy8Aa-kP"
   },
   "source": [
    "#### 5.1.1. Teoria\n",
    "\n",
    "Relembrando os conceitos apresentados anteriormente, Árvores de Decisão são compostas de uma estrutura similar a árvores que auxiliam no processo de decisão (tanto para classificação quanto para regressão). Essencialmente, esse método aprende uma hierarquia de ```if/else``` que levam a uma decisão, mantendo o conjunto de perguntas o menor possível.\n",
    "\n",
    "No video a seguir, exemplifica-se o processo de criação de uma Árvore de Decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnaOsyN35Jsz"
   },
   "source": [
    "##### Exemplo 5.1 \n",
    "\n",
    "[![IMAGE ALT TEXT](http://img.youtube.com/vi/eKD5gxPPeY0/0.jpg)](http://www.youtube.com/watch?v=eKD5gxPPeY0 \"Decision Tree 1: how it works\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krgU-eiYa-kT"
   },
   "source": [
    "Vejamos abaixo a árvore de decisão final do vídeo:\n",
    "\n",
    "<img src=https://cdn-images-1.medium.com/max/1600/0*9W0mx4ffV2qhNnm0.jpg width='500'/>\n",
    "\n",
    "O resultado final é uma árvore com *nós de decisão* e *nós folha*. Um nó de decisão (como *Outlook*) possui uma ou mais ramificações (como Sunny, Overcast e Rain). Um nó folha (como Yes ou No) representa uma classificação ou decisão. O nó de decisão no topo da árvore corresponde ao melhor preditor e é chamado de nó raíz.\n",
    "\n",
    "Para descrever o problema na terminologia de aprendizado de máquina, poderíamos dizer que o modelo distingue entre duas classes (jogar ou não jogar - yes ou no) usando três features/variáveis: outlook, humidity e wind.\n",
    "\n",
    "O importante aqui é entender como o algoritmo funciona. Porém construí-lo manualmente seria difícil e perderia todo o sentido do aprendizado de máquina automático.\n",
    "\n",
    "Como pode-se imaginar, existem diferentes algoritmos para construir uma árvore de decisão, porém os principais seguem a mesma linha de raciocínio. Se você notar do vídeo, árvores de decisão utilizam a estratégia dividir para conquistar, pois ele divide o problema (dados de entrada) em pequenos outros problemas (subconjuntos de dados) recursivamente até atingir uma condição de parada e ramificar nos nós de decisão. Os algoritimos mais comuns são ```CART``` e ```ID3```.\n",
    "\n",
    ">**Condições de Parada**: uma árvore de decisão (DT) vai parar suas chamadas recursivas caso o nó atual atinja algum dos critérios de parada do modelo, definidos pelos seus hiperparâmetros. Alguns critérios mais conhecidos são, por exemplo, o ganho de informação (explicado em maior detalhe adiante), a profundidade da árvore e a quantidade de elementos nos nós\n",
    "\n",
    "Mas como o algoritmo escolhe quais features serão as primeiras a serem usadas? O critério mais comum que o algoritmo utiliza para selecionar qual feature será usada é baseada na **impureza** gerada ao selecionar a variável. Existem duas maneiras principais de se medir a impureza: ganho de informação (information gain, ou IG) e impureza Gini. Ao passo que o algoritmo ```CART``` usa o Gini, o ```ID3``` usa IG.\n",
    "\n",
    "A medida Gini depende de uma métrica chamada **Gini Index**, ou índice de Gini, calculada da seguinte maneira:\n",
    "\n",
    "$$\\textit{Gini_index}(t) = 1 - \\sum_{j=1}^{c}p_j(t)^2$$\n",
    "\n",
    "onde $c$ é o número de classes e $p_j$ é a fração de dados de classe $j$ no conjunto no nó de decisão $t$. Ele varia de 0 a 0.5 para tarefas de classificação binária, onde quanto menos melhor (menos impuro).\n",
    "\n",
    "A impureza de Gini é então calculado como a média ponderada dos índices dos $k$ nós criados pela divisão:\n",
    "\n",
    "$$\\textit{Gini_average} = \\sum_{t=1}^{k}p(t) \\; Gini\\_index(t)$$\n",
    "\n",
    "A medida **IG** depende de outra métrica chamada **entropia (H)** e pode ser obtida a partir das fórmulas abaixo:\n",
    "\n",
    "$$\\textit{Entropia} = H(S) = -\\sum_{j=1}^{c}p_j\\log p_j$$\n",
    "\n",
    "e\n",
    "\n",
    "$$\\textit{Information Gain} = IG(A,S) = H(S) -\\sum_{t\\epsilon T}p(t)H(t)$$\n",
    "\n",
    "onde $H(S)$ é a entropia do conjunto $S$, $T$ são os subconjuntos criados a partir da separação do conjunto $S$ pelo atributo $A$, $p(t)$ é a proporção do número de elementos em $t$ em relação ao número de elementos no conjunto $S$ e $H(t)$ é a entropia do subconjunto $t$. Ele varia de 0 a 1, onde quanto maior, melhor (maior ganho de informação).\n",
    "\n",
    "Independente do critério selecionado para o algoritmo, a DT pode ser generalizada como:\n",
    "\n",
    "```\n",
    "1. Calcular a impureza (entropia ou gini index) para o conjunto de dados\n",
    "2. Para cada atributo/feature:\n",
    "       1. Calcular a Entropia ou Gini_index para todos os valores categóricos\n",
    "       2. Obter a média da entropia de informação para o atributo corrente\n",
    "       3. Calcular IG ou Gini_average\n",
    "3. Selecionar o melhor atributo baseado no IG ou Gini_average.\n",
    "4. Repetir até atingir uma condição de parada.\n",
    "```\n",
    "\n",
    "Isto é basicamente como uma DT é implementada em Python. Como veremos nas próximas subseções, o ```scikit-learn``` fornece ambos os critérios Gini e IG como parâmetro da função ```DecisionTreeClassifier```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eF9heQHja-kU"
   },
   "source": [
    "#### 5.1.2. Código em Python e Avaliação\n",
    "\n",
    "Usaremos o ```DecisionTreeClassifier``` do ```scikit-learn``` para construir nossos modelos de árvore.\n",
    "\n",
    "Primeiro, vamos importar tudo que precisamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fgjaYxFwa-kV"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzpPTv4ya-kZ"
   },
   "source": [
    "Lembre que já realizamos o split dos diferentes conjuntos de dados. Então basta criarmos nosso modelo de árvore.\n",
    "\n",
    "As etapas básicas são:\n",
    "\n",
    "- Criar um objeto de árvore de decisão com hiperparâmetros definidos. Como a tarefa é de classificação, usaremos o ```DecisionTreeClassifier```. Você pode ver todos os argumentos disponíveis para o método [aqui](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n",
    "- Usar o método ```.fit()``` para treinar.\n",
    "- Usar o método ```.predict()``` para usar o modelo fitado para previsão.\n",
    "\n",
    "Alguns hiperparâmetros importantes aqui são:\n",
    "- **max_depth(default=None)**: A profundidade máxima da árvore. Se None, então todos os nós serão expandidos até que as folhas sejam puras ou até que todas as folhas contenham apenas min_samples_split amostras\n",
    "- **min_samples_split(default=2)**: O número mínimo de amostras necessárias para ramificar um nó interno\n",
    "- **min_samples_leaf(default=1)**: O número mínimo de amostras necessárias para ser um nó folha\n",
    "- **max_features(default=None)**: O número de features a ser considerado para realizar a melhor quebra\n",
    "- **random_state(default=None)**: semente usada para o gerador de números aleatórios\n",
    "\n",
    "Para começar, vamos construir o modelo com os valores padrões dos hiperparâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "executionInfo": {
     "elapsed": 1871,
     "status": "ok",
     "timestamp": 1604405334367,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "OwXxJEi1a-ka",
    "outputId": "89a75ada-a611-4b06-db6d-6d034490204c"
   },
   "outputs": [],
   "source": [
    "# DECISION TREE MODEL 1\n",
    "\n",
    "# Gerar um objeto árvore usando uma semente para resultados reproduzíveis\n",
    "tree_1 = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "# Fitar o modelo usando o dataset de treino\n",
    "tree_1.fit(X_train, y_train)\n",
    "\n",
    "# Prever no dataset de validação\n",
    "y_pred = tree_1.predict(X_val)\n",
    "\n",
    "# Calcular e printar métricas\n",
    "print(\"Acurácia no conjunto de treino: {:.3f}\".format(tree_1.score(X_train, y_train)))\n",
    "print(\"Acurácia no conjunto de validação: {:.3f}\".format(tree_1.score(X_val, y_val)))\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "print(\"Área sob a curva ROC: {:.3f}\".format(roc_auc_score(y_val, y_pred)))\n",
    "\n",
    "# Plotar importância das features\n",
    "# Avalia quão importante é cada variável para as decisões que a árvore fornece\n",
    "# Corresponde a um número entre 0 e 1 para cada feature, onde 0 significa não usada e 1\n",
    "# \"perfeitamente prevê a resposta\". A importância das features sempre somam 1\n",
    "def plot_feature_importances_cancer(model):\n",
    "    n_features = cancer.data.shape[1]\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), cancer.feature_names)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.ylim(-1, n_features)\n",
    "    \n",
    "plot_feature_importances_cancer(tree_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGkKdAULa-kd"
   },
   "source": [
    "Já de cara, temos uma acurácia de 100% no dataset de treino e 92,3% no de validação, com um AUC de 0,932! Se você lembrar das aulas anteriores, vai perceber que isto é um claro indicativo de *overfitting*. Isto ocorre porque os valores padrões dos hiperparâmetros não limitam a árvore de crescer indefinidamente, fazendo com que o modelo consiga memorizar perfeitamente todos os pontos do conjunto de treino.\n",
    "\n",
    "Para evitar isto, podemos usar uma técnica chamada **pre-prunning**, que faz com que a árvore pare de crescer indefinidamente. Existem diferentes maneiras de realizar isto, mas a principal é de limitar o hiperparâmetro ```max_depth```, isto é limitar a profundidade máxima que a árvore pode alcançar.\n",
    "\n",
    "Vamos construir um outro modelo, mas agora setando ```max_depth = 4```, o que faz com que apenas três questões possam ser dispostas sucessivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "executionInfo": {
     "elapsed": 1818,
     "status": "ok",
     "timestamp": 1604405335109,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "c6zFUyUOa-ke",
    "outputId": "8a2a76b9-26b6-42af-df35-ffa02e3e770a"
   },
   "outputs": [],
   "source": [
    "# DECISION TREE MODEL 2\n",
    "\n",
    "# Gerar um objeto árvore usando uma semente para resultados reproduzíveis\n",
    "tree_2 = DecisionTreeClassifier(random_state=seed, max_depth=4)\n",
    "\n",
    "# Fitar o modelo usando o dataset de treino\n",
    "tree_2.fit(X_train,y_train)\n",
    "\n",
    "# Prever no dataset de validação\n",
    "y_pred = tree_2.predict(X_val)\n",
    "\n",
    "# Calcular e printar métricas\n",
    "print(\"Acurácia no conjunto de treino: {:.3f}\".format(tree_2.score(X_train, y_train)))\n",
    "print(\"Acurácia no conjunto de validação: {:.3f}\".format(tree_2.score(X_val, y_val)))\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "print(\"Área sob a curva ROC: {:.3f}\".format(roc_auc_score(y_val, y_pred)))\n",
    "\n",
    "# Plotar importância das variáveis\n",
    "plot_feature_importances_cancer(tree_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MN4oxhVza-ki"
   },
   "source": [
    "Vemos que o novo conjunto de hiperparâmetros diminui tanto a acurácia do conjunto de treino quanto de validação. Porém a diferença notável é que ambos estão mais próximos, indicando um modelo menos sobreajustado (overfitted), ou seja, a performance em dados já vistos é um pouco mais similar à performance em dados novos.\n",
    "\n",
    "É possível melhorar ainda mais a performance? Podemos manualmente tentar diferentes combinações e escolher aquela que garante a melhor métrica. Porém isto é lento e não escalável. Para ajudar nesta tarefa, existem técnicas automáticas como o *grid-search* (busca em grade) para encontrar o melhor conjunto de valores de hiperparâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3926,
     "status": "ok",
     "timestamp": 1604405337830,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "hm4bR0Eua-kj",
    "outputId": "4ef3d43f-1361-4ab1-b207-718f41615291"
   },
   "outputs": [],
   "source": [
    "# DECISION TREE MODEL 3 (com GridSearch)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir os possiveis valores para cada hiperparametro para serem explorados\n",
    "params = {'max_depth': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "          'min_samples_split': [2, 3, 4, 5, 6],\n",
    "          'min_samples_leaf': [1, 2, 3]}\n",
    "\n",
    "# Criar objeto com o DecisionTreeClassifier\n",
    "tree_3 = DecisionTreeClassifier(random_state=seed)\n",
    "\n",
    "# Criar objeto KFold com StratifiedKFold para validação cruzada\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "\n",
    "# Criar um objeto de grade de busca com GridSearchCV\n",
    "grid_search = GridSearchCV(tree_3, param_grid=params, scoring='roc_auc',\n",
    "                           cv=skf.split(X_training, y_training))\n",
    "\n",
    "# Treinar o modelo com o grid search\n",
    "grid_search.fit(X_training, y_training)\n",
    "\n",
    "# Printar a melhor combinação de hiperparâmetros\n",
    "print('Melhores hiperparâmetros:')\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "executionInfo": {
     "elapsed": 3573,
     "status": "ok",
     "timestamp": 1604405337831,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "rTKcAC26a-kp",
    "outputId": "2acb3d21-2e98-4352-fa53-258b5cf4053b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Gera uma árvore com as melhores combinações de hiperparâmetros\n",
    "tree_3 = DecisionTreeClassifier(random_state=seed, max_depth=grid_search.best_params_['max_depth'],\n",
    "                                min_samples_split=grid_search.best_params_['min_samples_split'],\n",
    "                                min_samples_leaf=grid_search.best_params_['min_samples_leaf'])\n",
    "\n",
    "# Fita o modelo com o dataset de treino\n",
    "tree_3.fit(X_train, y_train)\n",
    "\n",
    "# Usa o modelo para prever o conjunto de validação\n",
    "y_pred = tree_3.predict(X_val)\n",
    "\n",
    "# Calcular e printar métricas\n",
    "print(\"Acurácia no conjunto de treino: {:.3f}\".format(tree_3.score(X_train, y_train)))\n",
    "print(\"Acurácia no conjunto de validação: {:.3f}\".format(tree_3.score(X_val, y_val)))\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "print(\"Área sob a curva ROC: {:.3f}\".format(roc_auc_score(y_val, y_pred)))\n",
    "\n",
    "# Plotar importância das variáveis\n",
    "plot_feature_importances_cancer(tree_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWOfIMdIa-kv"
   },
   "source": [
    "Vemos que usando Grid Search, o hiperparâmetro ```min_samples_leaf``` foi alteardo de 1 para 3 automaticamente, o que proporcionou melhores métricas para o modelo final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dS1PWUaoa-kw"
   },
   "source": [
    "### 5.2. Regressão Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSNAbQksa-kx"
   },
   "source": [
    "#### 5.2.1. Teoria\n",
    "Regressão logística é um método estatístico para prever classes binárias. O resultado do modelo pode ser interpretado como uma probabilidade da amostra corresponder à classe positiva.\n",
    "\n",
    "O modelo é uma ligeira modificação da regressão linear onde a variável resposta é categórica em natureza e o output é passado por uma função logística."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqnDv_w5a-ky"
   },
   "source": [
    "**Equação da Regressão Logística**\n",
    "<center>\n",
    "$y = \\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{2}+ ... + \\beta_{n}x_{n}$\n",
    "</center>\n",
    "\n",
    "Onde $y$ é a variável dependente (ou resposta) e $x_1$, $x_2$ ... até $x_n$ são as variáveis independentes (ou explanatórias).\n",
    "\n",
    "<br>\n",
    "\n",
    "**Função Sigmoide/Logística**\n",
    "<center>\n",
    "$p = \\frac{1}{1+e^{-y}}$\n",
    "</center>\n",
    "\n",
    "Aplicando a função sigmoide na regressão linear, obtêm-se a regressão logística:\n",
    "<center>\n",
    "$p = \\frac{1}{1+e^{-(\\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{2}+ ... + \\beta_{n}x_{n})}}$\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p51gQAzsa-kz"
   },
   "source": [
    "**Regressão Linear x Regressão Logística**\n",
    "\n",
    "Ao passo que a variável resposta da regressão linear não tem restrição de valores, a regressão logística tem sua saída limitada entre 0 e 1. Desta maneira, enquanto a primeira é interessante para problemas como previsão de preço de casas, a segunda é útil para problemas de classificação, onde a variável resposta pode ser interpretada como uma probabilidade (no caso do dataset em questão nesta aula, a probabilidade de que um câncer seja maligno). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xh3Fk8mta-k2"
   },
   "source": [
    "**Vantagens**\n",
    "\n",
    "Dado sua natureza simples e eficiente, não necessita poder computacional muito grande, é de fácil implementação, altamente interpretável e portanto é muito utilizada.\n",
    "\n",
    "**Desvantagens**\n",
    "\n",
    "Não consegue lidar com uma quantidade muito grande de variáveis categóricas. É vulnerável ao overfitting. Não lida com relações não-lineares entre variável explanatória e variável resposta. Não performa bem com features altamente correlacionadas entre si."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFoQ_nBEa-k3"
   },
   "source": [
    "#### 5.2.2. Código em Python e Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1845,
     "status": "ok",
     "timestamp": 1604405337832,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "HH-COILXa-k5",
    "outputId": "ac11ea17-b1f3-41ab-f7f5-6278599fe1b1"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Treino do modelo\n",
    "# O otimizador 'liblinear' é utilizado para um conjunto de dados pequeno\n",
    "logreg = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    "print(\"Acurácia no conjunto de treino: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
    "print(\"Acurácia no conjunto de validação: {:.3f}\".format(logreg.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22zCHrX2a-lA"
   },
   "source": [
    "Olhando para as métricas, a Regressão Logística performa muito bem para esta tarefa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1297,
     "status": "ok",
     "timestamp": 1604405337833,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "KP3pJj_Oa-lB",
    "outputId": "c148f1a6-8649-4f06-e1bd-52cede25bd0f"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_val, logreg.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 1710,
     "status": "ok",
     "timestamp": 1604405338552,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "QFBUH4qNa-lE",
    "outputId": "ad687afc-a627-4c26-b587-f3ea1aa40cf6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "logit_roc_auc = roc_auc_score(y_val, logreg.predict(X_val))\n",
    "fpr, tpr, thresholds = roc_curve(y_val, logreg.predict_proba(X_val)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Regressão Logística (área = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlabel('Taxa de Falsos Positivos')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O20Hww2fa-lJ"
   },
   "source": [
    "Regularização é um processo de adição de informação (penalidade) em funções de custo/perda de forma a evitar o overfitting na aprendizagem do modelo. Na regressão logística, o hiperparâmetro que controla a força da regularização é chamado C, e valores maiores correspondem a menos regularização.\n",
    "\n",
    "Em outras palavras, quando se usa altos valores do hiperparâmetro C, a regressão logística tenta fitar o dataset de treino o melhor possível, independente da magnitude que seus parâmetros adquiram; já com valores baixos de C, o modelo é penalizado por valores altos de parâmetros aprendidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlGNA-zza-lK"
   },
   "source": [
    "<center>\n",
    "\n",
    "![alt](https://cdn.analyticsvidhya.com/wp-content/uploads/2017/06/Qc281.jpg)\n",
    "\n",
    "\n",
    "Limiares de decisão para diferentes valores de C\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yUzHmH8a-lK"
   },
   "source": [
    "A imagem à esquerda corresponde ao limiar de decisão (conjunto de pontos onde o modelo indica uma probabilidade igual de ser tanto da classe positiva quanto da negativa) do modelo ao ser treinado com uma alta regularização (portanto, um valor baixo de C). É possível ver um underfitting uma vez que o modelo não é capaz de captar o padrão curvo das amostras positivas no espaço das variáveis, resultando em várias previsões erradas.\n",
    "\n",
    "A imagem da direita corresponde ao limiar de decisão do modelo ao ser treinado com uma baixa regularização (portanto, um alto valor de C). Neste caso, o overfitting ocorre claramente, pois o modelo tenta delinear perfeitamente todos os pontos, sendo sujeito ao ruído e variância dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zacj335Ca-lL"
   },
   "source": [
    "O valor padrão de C=1 já fornece uma boa performance com uma acurácia de aproximadamente 95% em ambos os conjuntos de treino e validação. Vamos verificar o comportamento do modelo ao alterar este hiperparâmetro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 823,
     "status": "ok",
     "timestamp": 1604405926688,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "EhUFFgi6a-lM",
    "outputId": "0082bd65-8c49-4b60-dbbf-9db6bdcb263a"
   },
   "outputs": [],
   "source": [
    "logreg10 = LogisticRegression(C=100).fit(X_train, y_train)\n",
    "print(\"Acurácia no conjunto de treino: {:.3f}\".format(logreg10.score(X_train, y_train)))\n",
    "print(\"Acurácia no conjunto de validação: {:.3f}\".format(logreg10.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 734,
     "status": "ok",
     "timestamp": 1604405929632,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "IE40YvUMa-lO",
    "outputId": "d97ab7e0-e1a7-4f21-daf4-b014ae46c327"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_val, logreg10.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01iO1xpRa-lS"
   },
   "source": [
    "Com um C=100 não vemos uma diferença significativa nos resultados, o que indica que diminuir ainda mais a regularização (aumentar a complexidade do modelo) não deve ajudar.\n",
    "\n",
    "Vamos agora investigar o que ocorre ao aumentar a regularização (diminuir C) e consequentemente diminuir a complexidade do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1224,
     "status": "ok",
     "timestamp": 1604405931063,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "J_H5QYpka-lS",
    "outputId": "93c22e02-1dac-4448-bdeb-d1450175b58c"
   },
   "outputs": [],
   "source": [
    "logreg001 = LogisticRegression(C=0.01,solver='liblinear').fit(X_train, y_train)\n",
    "print(\"Acurácia no conjunto de treino: {:.3f}\".format(logreg001.score(X_train, y_train)))\n",
    "print(\"Acurácia no conjunto de validação: {:.3f}\".format(logreg001.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OktYmpNka-lZ"
   },
   "source": [
    "Vemos uma queda na acurácia do conjunto de validação, o que indica um pequeno underfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8F5tdu7a-lb"
   },
   "source": [
    "Como a busca manual pelo melhor valor do hiperparâmetro C seria muito trabalhosa, podemos novamente usar novamente o ```GriSeachCV```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7728,
     "status": "ok",
     "timestamp": 1604405910943,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "KgXgz_FQa-lc",
    "outputId": "1bc61a0a-c439-48bc-a290-eca3ddec98a9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Generate a range with different values for C parameter\n",
    "grid = {\"C\": np.arange(1,150,5)}\n",
    "logreg_cv = GridSearchCV(LogisticRegression(solver='liblinear'), grid, cv=10)\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Melhores hiperparâmetros: \", logreg_cv.best_params_)\n",
    "print(\"Acurácia:\", logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cU8Ifgl3a-ll"
   },
   "source": [
    "### 5.3. Métodos Compostos (*Ensemble Methods*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1. Teoria\n",
    "\n",
    "Métodos Compostos, como o nome sugere, são métodos em que são combinados diferentes modelos mais simples (*weak learners*) para produzir um modelo de maior capacidade preditiva (*strong learner*). Pensando no universo das árvores de decisão, o principio por trás desses métodos é o de que a união de diversas árvores menores possui uma capacidade preditiva melhor que uma grande árvore (mais complexa).\n",
    "\n",
    "Para entender um pouco melhor este principio, é importante conhecer o *trade off* entre o viés e a variância:\n",
    "\n",
    "> **Viés (*bias*)**: É a tendência de o modelo aprender consistentemente uma generalização incorreta. Em outras palavras, o modelo não consegue capturar as relações corretas entre as variáveis e o objeto a ser predito. Portanto, quando o viés é alto o modelo não consegue aprender (*underfitting*).\n",
    "\n",
    "> **Variância**: A variância é a sensibilidade de um modelo ao ser usado com outros datasets diferentes do treinamento. Se o modelo é muito sensível aos dados de treinamento, ou seja, identificou tão bem a relação entre os dados de treinamento que quando colocado em teste irá errar justamente a variação que existe entre os datasets.\n",
    "\n",
    "De maneira mais didática, podemos ilustrar estes conceitos com as imagens abaixo:\n",
    "\n",
    "<center>\n",
    "    \n",
    "![alt](https://miro.medium.com/max/914/1*1kOlhkPVgb5upFUaRYbjIQ.png)\n",
    "\n",
    "   \n",
    "</center>\n",
    "Combinação entre o viés e a variancia\n",
    "\n",
    "<center>\n",
    "    \n",
    "![alt](https://miro.medium.com/max/1560/1*Ah1N6gqkA0zZfpSoS9erAA.png)\n",
    "\n",
    "Predições com alto viés e alta variância\n",
    "</center>\n",
    "\n",
    "Dessa forma, nota-se que um bom modelo deve performar com um baixo viés e uma baixa variância, ou seja, ser capaz de identificar e generalizar padrões.\n",
    "\n",
    "Modelos muito simples, com baixa complexidade são mais sucetiveis a apresentarem um alto viés, ou seja, não aprenderem as relações existentes nos dados. Por outro lado, modelos consideravelmente complexos (muitas variaveis preditoras ou árvores de decisão extensas) podem gerar resultados com alta variância, ou seja, podem aprender padrões que podem não ser reais e consequentemente não apresentar uma capacidade de generalização. Esse trade-off entre a variância e o viés é representado na imagem abaixo:\n",
    "\n",
    "<center>\n",
    "    \n",
    "![alt](https://miro.medium.com/max/490/0*UDp6phojWvlixHO9)\n",
    "\n",
    "*Trade-off* entre o viés (*bias*) e variancia\n",
    "</center>\n",
    "\n",
    "Nota-se que o erro total do modelo é soma do viés com a variância e que conforme o modelo vai “aprendendo” (model complexity aumenta) temos um momento de baixa e logo depois o erro volta a crescer.\n",
    "\n",
    "É muito comum modelos que aprendem muito bem no conjunto de treino, mas acabam apresentando *Overfitting*. Isso faz com que o modelo esteja do lado direito desse diagrama, entretanto, o ideal é que fique mais próximo ao meio. Então para diminuir a variância acrescentamos um pouquinhos de viés, assim ele “desaprende” o suficiente para conseguir generalizar e ser usado além dos dados de treino.\n",
    "\n",
    "Retornando à questão inicial da seção, este *trade-off* ilustra que aumentar a complexidade de um modelo pode implicar em uma perda de performance de predição. Portanto, quando temos diversas variaveis a disposição, por exemplo, utilizar uma unica árvore de decisão pode gerar um modelo excessivamente complexo. \n",
    "\n",
    "Nesse sentido, os métodos compostos (*ensemble methods*) buscam combinar modelos mais simples (também conhecidos como *base models*) para construir um modelo composto com melhor capacidade de predição. Cada *base model* possui certas especificidades que o fazem performar melhor sob determinadas circunstâncias. No momento em que combinamos estes modelos (que por serem simples demais podem não performar bem por si mesmos) passamos a cobrir uma maior variedade de situações, explorando as vantagens de cada *base model* e complementando seus eventuais pontos de fragilidade. A ideia é similar a utilizar pequenas peças (*base models*) para construir um modelo composto muito mais robusto (*strong learner*) \n",
    "\n",
    "As três principais formas de gerar os modelos compostos são: \n",
    "\n",
    "> **Bagging**: Método em que são combinados *weak learners* (normalmente homogêneos, mesmo algoritmo), organizados de maneira paralela e independente, sendo o *output* final determinado por um processo de ponderação dos *outputs* de cada *learner*.\n",
    "<center>\n",
    "    \n",
    "![alt](https://miro.medium.com/max/3630/1*7XVde-bMixpKf8mj61qhJQ@2x.png)\n",
    "\n",
    "   \n",
    "</center>\n",
    "\n",
    "> **Boosting**:  Método em que são combinados *weak learners* (normalmente homogêneos, mesmo algoritmo), organizados de maneira sequêncial e adaptativa, ou seja, cada *learner* é escolhido de modo a compensar os eventuais erros do anterior, sendo combinados de uma maneira deterministica para produzir o *output* final.\n",
    "<center>\n",
    "    \n",
    "![alt](https://miro.medium.com/max/3630/1*VGSoqefx3Rz5Pws6qpLwOQ@2x.png)\n",
    "\n",
    "</center>\n",
    "    \n",
    "> **Stacking**: Método em que são combinados *weak learners* (normalmente heterogêneos, algoritmos diferentes), organizados de maneira paralela, de modo que seus *outputs* são utilizados para treinar um meta-modelo que finalmente produz o *output* final.\n",
    "<center>\n",
    "    \n",
    "![alt](https://miro.medium.com/max/700/1*ZucZsXkOwrpY2XaPh6teRw@2x.png)\n",
    "\n",
    " </center>\n",
    "\n",
    "A escolha do método a ser utilizado depende da especificidade do problema e da relação entre as variáveis e o objeto a ser predito. Em geral, testam-se os diferentes algoritmos e escolhe-se aquele que apresentou a melhor performance e capacidade de generalização. Caso queira complementar o aprendizado, recomenda-se a leitura dos artigos:  [1](https://medium.com/ml-research-lab/ensemble-learning-the-heart-of-machine-learning-b4f59a5f9777),[2](https://towardsdatascience.com/ensemble-methods-in-machine-learning-what-are-they-and-why-use-them-68ec3f9fef5f), [3](https://towardsdatascience.com/basic-ensemble-learning-random-forest-adaboost-gradient-boosting-step-by-step-explained-95d49d1e2725#:~:text=Random%20forest%20is%20an,tree%20as%20the%20individual%20model.)\n",
    "<center>\n",
    "    \n",
    "![alt](https://miro.medium.com/max/700/1*P0ns6A56MtpGFMQ2g47IYA.png)\n",
    "\n",
    " </center>\n",
    "\n",
    "Os diferentes métodos de composição são a base de alguns dos modelos mais utilizados na indústria. O algoritmo de *Random Forest*, por exemplo, utiliza o método de *Bagging*, enquanto o *AdaBoost* e o *XGBoost* utilizam o método de *Boosting*. \n",
    "\n",
    "Na próxima seção iremos utilizar o *XGBoost (Extreme Gradient Boosting)* para tentar resolver o nosso problema de diagnóstico, portanto, é importante que o conceito de *boosting* seja bem compreendido. No video abaixo explora-se um pouco mais no detalhe este método:\n",
    "\n",
    "[![IMAGE ALT TEXT](http://img.youtube.com/vi/GM3CDQfQ4sw/0.jpg)](http://www.youtube.com/watch?v=GM3CDQfQ4sw \"Decision Tree 1: how it works\")\n",
    "\n",
    "Caso queira se aprofundar ainda mais, assista a esses outros vídeos: [1](https://www.youtube.com/watch?v=ErDgauqnTHk) ou [2](https://www.youtube.com/watch?v=jxuNLH5dXCs).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8D8V-HiOa-lu"
   },
   "source": [
    "#### 5.3.2. Código em Python e Avaliação\n",
    "\n",
    "O primeiro passo a se fazer é instalar a biblioteca do xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4067,
     "status": "ok",
     "timestamp": 1604406660861,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "xo0dDVsOa-lv",
    "outputId": "76e416c5-fa14-499a-d230-2a30b97eeb64"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRCIl8CLa-l1"
   },
   "source": [
    "Em seguida, importamos o modelo junto com algumas métricas de avaliação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hp2hVkK1a-l2"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hk7nCHJ4a-l8"
   },
   "source": [
    "Vamos então treinar nosso primeiro modelo de xgboost.\n",
    "\n",
    "As etapas básicas são:\n",
    "- Criar um objeto modelo xgboost com seus hiperparâmetros (como estamos tratando de um problema de classificação, usaremos o ```XGBClassifier```). Você pode ver todos os hiperparâmetros disponíveis [aqui](https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier) e mais detalhes sobre cada um deles [aqui](https://xgboost.readthedocs.io/en/latest/parameter.html#parameters-for-tree-booster).\n",
    "- Usar o método ```.fit()``` para treinar o modelo.\n",
    "- Usar o método ```.predict()``` para usar o modelo para prever novos dados.\n",
    "\n",
    "Alguns hiperparâmetros importantes que usaremos nessa aula são:\n",
    "- **objective \\[default=reg:squarederror\\]**: define o tipo de problema e a função objetivo a ser usada\n",
    "- **eval_metric \\[default according to objective\\]**: métrica de avaliação a ser usada junto com o conjunto de validação\n",
    "- **colsample_bytree \\[default=1\\]**: percentual de colunas a ser usado em cada árvore\n",
    "- **learning_rate \\[default=0.3\\]**: tamanho do passo de atualização no aprendizado\n",
    "- **max_depth \\[default=6\\]**: máxima profundidade de cada árvore\n",
    "- **alpha \\[default=0\\]**: termo de regularização L1 nos pesos (quanto maior, mais regularização)\n",
    "- **n_estimators \\[default=100\\]**: número de árvores para treinar\n",
    "\n",
    "Vamos primeiramente definir apenas ```objective``` e ```eval_metric``` de forma que o modelo seja treinado com o restante dos hiperparâmetros em seus valores padrão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 533
    },
    "executionInfo": {
     "elapsed": 1268,
     "status": "ok",
     "timestamp": 1604407265738,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "MWrvSP-ba-l9",
    "outputId": "e59a2561-fe81-4ee8-b1a7-098c0eb42d8f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# XGBoost 1\n",
    "\n",
    "# Criar um objeto XGBClassifier\n",
    "xgb_model_1 = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=seed, eval_metric=\"auc\",use_label_encoder=False)\n",
    "\n",
    "# Treinar o modelo usando o conjunto de treino\n",
    "xgb_model_1.fit(X_train,y_train)\n",
    "\n",
    "# Prever usando o conjunto de validação\n",
    "y_pred = xgb_model_1.predict(X_val)\n",
    "\n",
    "# Calcular e printar algumas métricas\n",
    "print(\"Acurácia no conjunto de treino: {:.3f}\".format(xgb_model_1.score(X_train, y_train)))\n",
    "print(\"Acurácia no conjunto de validação: {:.3f}\".format(xgb_model_1.score(X_val, y_val)))\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "print(\"Área abaixo da curva ROC: {:.3f}\".format(roc_auc_score(y_val, y_pred)))\n",
    "\n",
    "# Plotar a importância das variáveis\n",
    "xgb.plot_importance(xgb_model_1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-chpJcLaa-mE"
   },
   "source": [
    "Como podemos ver, o modelo obteve acurácia de 100% no dataset de treino e 95,7% no dataset de validação, indicando um overfit no treino, embora ainda sim com ótima performance no segundo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuvVXx5Ta-mL"
   },
   "source": [
    "Vejamos agora como usar a Cross Validation com o XGBoost. As principais diferenças do que acabamos de fazer são:\n",
    "- Criar uma ```DMatrix```, estrutura de dados interna para o xgboost que otimiza a memória usada e velocidade de treino\n",
    "- Usar o ```StratifiedKFold``` para criar os grupos para a validação cruzada, passando o número de splits ```n_splits```\n",
    "- Usar o método ```xgb.cv``` para realizar a validação cruzada. Internamente, isto é realizado a cada iteração de boosting, portanto também é retornado o número ótimo de árvores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "executionInfo": {
     "elapsed": 1213,
     "status": "ok",
     "timestamp": 1604414418355,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "rG930jPfa-mN",
    "outputId": "0f8bd8cf-dbe5-4b34-eac5-f2a246c10376"
   },
   "outputs": [],
   "source": [
    "# XGBoost with Cross Validation\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Criar a DMatrix\n",
    "data_dmatrix = xgb.DMatrix(data=X_training, label=y_training)\n",
    "\n",
    "# Criar modelo com o XGBClassifier\n",
    "xgb_model_cv = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=seed, eval_metric=\"auc\",\n",
    "                                 colsample_bytree=0.3, learning_rate=0.1, max_depth=4, alpha=5, n_estimators=10,use_label_encoder=False)\n",
    "\n",
    "# Salvar parâmetros em uma variável\n",
    "params = xgb_model_cv.get_xgb_params()\n",
    "\n",
    "# Criar objeto StratifiedKFold e rodar validação cruzada\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, folds=skf, num_boost_round=5000,\n",
    "                    early_stopping_rounds=10, metrics=\"auc\", stratified=True, seed=seed)\n",
    "\n",
    "# Ajustar o melhor número de árvores em n_estimators\n",
    "xgb_model_cv.set_params(n_estimators=cv_results.shape[0])\n",
    "\n",
    "# Treinar o modelo com os datasets de treino + validação\n",
    "xgb_model_cv.fit(X_training, y_training)\n",
    "\n",
    "# Printar a AUC média nos datasets de treino e teste\n",
    "print(\"AUC média no dataset de treino: {:.3f} +/- {:.3f}\".format(cv_results.loc[cv_results.shape[0]-1, 'train-auc-mean'],\n",
    "                                                                 cv_results.loc[cv_results.shape[0]-1, 'train-auc-std']))\n",
    "print(\"AUC média no dataset de teste: {:.3f} +/- {:.3f}\".format(cv_results.loc[cv_results.shape[0]-1, 'test-auc-mean'],\n",
    "                                                                cv_results.loc[cv_results.shape[0]-1, 'test-auc-std']))\n",
    "\n",
    "# Plotar importância das variáveis\n",
    "xgb.plot_importance(xgb_model_cv)\n",
    "plt.show()\n",
    "\n",
    "# Mostrar as últimas iterações da validação cruzada\n",
    "cv_results.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rwag1PQfa-mS"
   },
   "source": [
    "Em seguida, vamos realizar o grid search para encontrar o melhor conjunto de valores para os hiperparâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 6350,
     "status": "ok",
     "timestamp": 1604416368912,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "OnKJafk6a-mT",
    "outputId": "3294d000-49f5-4cac-f278-c54449e0284c"
   },
   "outputs": [],
   "source": [
    "# XGBoost com Cross Validation\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define um conjunto de possíveis valores para os hiperparâmetros\n",
    "params = {'learning_rate': [0.1, 0.2, 0.3],\n",
    "          'alpha': [5, 10, 15],\n",
    "          'colsample_bytree': [0.1, 0.3, 0.5, 0.7, 1.0],\n",
    "          'max_depth': [3, 4, 5]}\n",
    "\n",
    "# Cria o modelo\n",
    "xgb_model_cv_gs = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=seed,\n",
    "                                    eval_metric=\"auc\", n_estimators=10,use_label_encoder=False)\n",
    "\n",
    "# Cria o grid search com validação cruzada estratificada\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "grid_search = GridSearchCV(xgb_model_cv_gs, param_grid=params, scoring='roc_auc',\n",
    "                           cv=skf.split(X_training, y_training))\n",
    "\n",
    "# Treina o modelo e printa os melhores hiperparâmetros\n",
    "grid_search.fit(X_training, y_training)\n",
    "print('\\n Melhores hiperparâmetros:')\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Obtém os resultados da validação cruzada\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "print(\"Acurácia média no conjunto de validação: {:.3f} +/- {:.3f}\".format(\n",
    "  cv_results[cv_results.rank_test_score == 1].mean_test_score.values[0],\n",
    "  cv_results[cv_results.rank_test_score == 1].std_test_score.values[0])\n",
    ")\n",
    "\n",
    "# Atribui os melhores valores para os hiperparâmetros\n",
    "xgb_model_cv_gs.set_params(learning_rate = grid_search.best_params_['learning_rate'],\n",
    "                           alpha = grid_search.best_params_['alpha'],\n",
    "                           colsample_bytree = grid_search.best_params_['colsample_bytree'],\n",
    "                           max_depth = grid_search.best_params_['max_depth'])\n",
    "\n",
    "# Treina o modelo usando os melhores hiperparâmetros\n",
    "xgb_model_cv_gs.fit(X_training, y_training)\n",
    "\n",
    "# Plota a importância das variáveis\n",
    "xgb.plot_importance(xgb_model_cv_gs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ir9Nebgza-mb"
   },
   "source": [
    "<a id=\"eval\"></a>\n",
    "## 6. Avaliação dos Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hVlC2mta-md"
   },
   "source": [
    "#### Exercício 6.1 \n",
    "\n",
    "Baseado na AUC de todos os modelos treinados, qual você escolheria como seu classificador final?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "exid": "6.1",
    "id": "V0EwddEGa-me"
   },
   "outputs": [],
   "source": [
    "AUC_Arvore  = ____\n",
    "AUC_RegLog  = ____\n",
    "AUC_XGBoost = ____\n",
    "\n",
    "print(\"AUC Arvore: {:.3f}\".format(AUC_Arvore))\n",
    "print(\"AUC RegLog: {:.3f}\".format(AUC_RegLog))\n",
    "print(\"AUC XGBoost: {:.3f}\".format(AUC_XGBoost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPf-21UBa-mi"
   },
   "source": [
    "Como falsos positivos e falsos negativos possuem significados reais completamente diferentes, existe sempre um trade-off entre eles. Tende-se normalmente a minimizar mais um em detrimento de outro de acordo com aquilo que vemos que tem mais impacto.\n",
    "\n",
    "#### Exercício 6.2  \n",
    "\n",
    "No caso do problema de câncer de mama tratado aqui, sabendo que uma classe positiva (valor 1) é um tecido diagnosticado como benigno. Qual é o significado de um falso positivo? E de um falso negativo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tpDir97a-mj"
   },
   "source": [
    "#### Exercício 6.3 \n",
    "\n",
    "Baseado na resposta anterior, que tipo de erro é preferível minimizar (falsos positivos ou falsos negativos) e por que?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y85oq_OZa-mk"
   },
   "source": [
    "#### Exercício 6.4 \n",
    "\n",
    "Com base na resposta anterior, escolha entre os modelos treinados, aquele que melhor satisfaz sua decisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zLvxnp2Xa-ml"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWRs-N9La-mo"
   },
   "source": [
    "Aqui vamos apresentar uma possível solução.\n",
    "\n",
    "Por um lado, se tivermos um falso positivo, estamos diagnosticando um tecido maligno como benigno. Isto é, estamos dizendo ao paciente que está tudo bem, enquanto na verdade não está. Neste caso, a pessoa vai provavelmente postergar um diagnóstico futuro, o que pode fazer com que a doença piore e que o tratamento seja mais drástico.\n",
    "\n",
    "De outro lado, se tivermos um falso negativo, estamos diagnosticando um tecido benigno como maligno. Em outras palavras, estamos dizendo ao paciente que ele está com câncer, quando na verdade não está. Neste caso, a pessoa sofrerá problemas de ansiedade, tendo um impacto negativo na sua saúde mental, e também estará sujeito a tratamentos como biopsia, em que uma parte ou todo o tecido será removido.\n",
    "\n",
    "Decidir que tipo de erro é uma questão delicada. Mas aqui focaremos em minimizar a quantidade de falsos positivos. Isto é, queremos maximizar a **precisão** (*precision*), ou seja, maximizar a taxa de acerto quando prevemos que o paciente tem um tecido maligno.\n",
    "\n",
    "<img src=https://cdn-images-1.medium.com/max/1200/1*uR09zTlPgIj5PvMYJZScVg.png width=500/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xpM6kbua-mo"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Realizar as previsões no dataset de teste\n",
    "y_tree_pred   = tree_3.predict(X_test)\n",
    "y_logreg_pred = logreg_cv.best_estimator_.predict(X_test)\n",
    "y_xgb_pred    = xgb_model_cv_gs.predict(X_test)\n",
    "\n",
    "# Printar a precisão de cada algoritmo\n",
    "print(precision_score(y_test, y_tree_pred))\n",
    "print(precision_score(y_test, y_logreg_pred))\n",
    "print(precision_score(y_test, y_xgb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHD_hdv-a-mt"
   },
   "source": [
    "Como a regressão logística e o modelo XGBoost dão performances similares, podemos usar outro critério de desempate. Se o modelo precisa rodar o mais rápido possível, poderíamos avaliar o tempo que cada um deles demora para realizar a classificação (em um diagnóstico médico, pode não fazer tanta diferença se os resultados ficarem prontos em 0,10 ou 0,15 segundos, mas isto pode com certeza fazer diferença para aplicações como carros autônomos).\n",
    "\n",
    "Se for necessário, por exemplo, a aprovação de um diretor para implementar o modelo desenvolvido, pode ser mais interessante o uso de um algoritmo que seja facilmente explanável e interpretável de forma que ele possa entender como o modelo está tomando as decisões. Isto é o que chamamos de **interpretabilidade de modelos**, e é considerado uma questão importante no momento em que um cientista de dados está reportando seus resultados a pessoas que não domimam muito o assunto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ncjXP4HYa-mt"
   },
   "source": [
    "#### Exercício 6.5\n",
    "\n",
    "Para este exercício, você vai seguir as instruções fornecidas e preencher os campos para construir seus próprios modelos e escolher entre o melhor deles. Para isso, usaremos dados de doadores prévios de sangue para prever quem doará novamente em Março de 2007. O dataset se chama *transfusion.csv*. Ele consiste de:\n",
    "- Recency: meses desde a última doação\n",
    "- Frequency: número total de doações antes de Março de 2007\n",
    "- \"Monetary\": valor total de sangue doado\n",
    "- Time: meses desde a primeira doação\n",
    "- donated: variável resposta binária indicando se a pessoa doou sangue em Março de 2007 (1 = doou, 0 = não doou)\n",
    "\n",
    "**Obs.:** este é um dataset mais \"real\" no sentindo em que os pontos não são facilmente separáveis por um modelo. Desta forma, em alguns algoritmos, variar os hiperparâmetros pode não ter uma influência significativa na performance. Sinta-se a vontade para brincar com as variáveis e fazer feature engineering e selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "exid": "6.5.1",
    "id": "67PMHgBYa-mu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.genfromtxt('transfusion.csv', delimiter=';', skip_header=1)\n",
    "\n",
    "# Separar a variável resposta\n",
    "X = np.delete(data, -1, 1)\n",
    "y = data[:, [-1]].ravel()\n",
    "\n",
    "print(\"X\", X.shape)\n",
    "print(\"y\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcjblVAKa-mx"
   },
   "source": [
    "Na célula a seguir, complete o código para realizar o split treino, validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "exid": "6.5.2",
    "id": "9Jh45uFWa-my"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 1\n",
    "\n",
    "#Construa os Datasets de Treino e Teste\n",
    "___, ___, ___, ___ = ___(X, y, random_state=seed, test_size=0.25, stratify=y)\n",
    "\n",
    "print(\"Conjunto de teste X\", X_test.shape)\n",
    "print(\"Conjunto de teste y\", y_test.shape)\n",
    "\n",
    "#Construa o Dataset de Validação\n",
    "___, ___, ___, ___ = ___(___, ___, random_state=___,\n",
    "                         test_size=0.33, stratify=y_training)\n",
    "\n",
    "print(\"Conjunto de treino X\", X_train.shape)\n",
    "print(\"Conjunto de treino y\", y_train.shape)\n",
    "print(\"Conjunto de validação X\", X_val.shape)\n",
    "print(\"Conjunto de validação y\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDMeKhFva-m5"
   },
   "source": [
    "Agora, use a célula abaixo para treinar uma árvore de decisão. Brinque com os hiperparâmetros para ver a influência de cada um na performance final. Atente-se para as métricas de avaliação para evitar o overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "exid": "6.5.3",
    "id": "npw5so4Wa-m7"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Árvore de decisão\n",
    "\n",
    "tree = ___(random_state=seed, _________)\n",
    "\n",
    "tree.___(___,___)\n",
    "\n",
    "y_pred_tree = tree.___(___)\n",
    "\n",
    "print(\"Acurácia no dataset de treino: {:.3f}\".format(tree.score(___, ___)))\n",
    "print(\"Acurácia no dataset de validação: {:.3f}\".format(tree.score(___, ___)))\n",
    "print(classification_report(___, ___))\n",
    "print(confusion_matrix(___, ___))\n",
    "print(\"AUC: {:.3f}\".format(roc_auc_score(___, ___)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfVHl9gWa-nA"
   },
   "source": [
    "Construa agora um modelo de regressão logística, tentando diferentes hiperparâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "exid": "6.5.4",
    "id": "boiKrwh9a-nA"
   },
   "outputs": [],
   "source": [
    "# Regressão logística\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = ___(___)\n",
    "\n",
    "logreg.___(___, ___)\n",
    "\n",
    "y_pred_logreg = logreg.___(___)\n",
    "\n",
    "print(\"Acurácia no dataset de treino: {:.3f}\".format(logreg.score(___, ___)))\n",
    "print(\"Acurácia no dataset de validação: {:.3f}\".format(logreg.score(___, ___)))\n",
    "print(classification_report(___, ___))\n",
    "print(confusion_matrix(___, ___))\n",
    "print(\"AUC: {:.3f}\".format(roc_auc_score(___, ___)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKFTSJrEa-nD"
   },
   "source": [
    "Como último modelo, treine um XGBoost, novamente alterando os hiperparâmetros e avaliando seu efeito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "exid": "6.5.5",
    "id": "aE9rEpDDa-nD"
   },
   "outputs": [],
   "source": [
    "# XGBOOST\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = ___.___(objective=___, random_state=seed, eval_metric=___, ___________)\n",
    "\n",
    "xgb_model.___(___,___)\n",
    "\n",
    "y_pred_xgb = xgb_model.___(___)\n",
    "\n",
    "print(\"Acurácia no dataset de treino: {:.3f}\".format(xgb_model.score(___, ___)))\n",
    "print(\"Acurácia no dataset de validação: {:.3f}\".format(xgb_model.score(___, ___)))\n",
    "print(classification_report(___, ___))\n",
    "print(confusion_matrix(___, ___))\n",
    "print(\"AUC: {:.3f}\".format(roc_auc_score(___, ___)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kl50JT4ma-nH"
   },
   "source": [
    "Avalie todos os modelos construídos no dataset de teste e escolha aquele que melhor performa de acordo com sua métrica de avalição escolhida (não há necessidade de manter a métrica usada. Sinta-se livre para escolher qualquer outra). Explique brevemente a razão da escolha da métrica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "exid": "6.5.6",
    "id": "gBEj09ORa-nI"
   },
   "outputs": [],
   "source": [
    "#Defina a métrica e avalie os modelos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCvTenGga-nN"
   },
   "source": [
    "<a id=\"multiclass\"></a>\n",
    "## 7. Classificação Multiclasse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XALKaGTva-nO"
   },
   "source": [
    "### 7.1. Definição do Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9cYvb-oa-nP"
   },
   "source": [
    "Primeiramente, cabe distinguirmos os conceitos de classificação multiclasse e multirótulo (multilabel).\n",
    "\n",
    "* **Classificação multiclasse** corresponde a uma classificação em mais de duas classes. Exemplos: classificar um conjunto de imagem de frutas que podem ser laranjas, maçãs ou peras. Classificação multiclasse assume que cada amostra pertence a uma e apenas uma classe (isto é, são mutualmente excludentes). Uma laranja não pode ser uma pera ao mesmo tempo.\n",
    "\n",
    "* **Classificação multilabel** atribui a cada amostra um conjunto diferente de rótulos. Isto pode ser pensado como prever propriedades de um ponto de dado que não sejam mutualmente excludentes. Exemplos: gêneros de filmes e tópicos de um documento. Um filme pode ser tanto comédia como romance e um texto pode falar tanto sobre política quanto sobre educação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrrUscxDa-nS"
   },
   "source": [
    "Muitos dos algoritmos usados para classificação binária também servem para classificação multiclasse (e também para tarefas de regressão).\n",
    "\n",
    "Outros algoritmos, como Suport Vector Machines (SVM) ou preditores lineares (como a regressão logística), são estritamente para problemas binários. Entretanto, existem diferentes estratégias para realizar uma classificação multiclasse com preditores binários."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTsfaWg5a-nT"
   },
   "source": [
    "* Um contra todos (One-Versus-All) é uma estratégia em que um classificador é treinado para cada classe no dataset (a classe correspondente é tratada como positiva e todas as outras, negativas). Então, a amostra é fornecida como input para todos os classificadores e aquele que retorna a maior probabilidade é escolhido como previsão.\n",
    "\n",
    "* Um contra um (One-Versus-One) é uma estratégia que treina diferentes modelos para cada par de classes. Desta forma, se existem N classes, são necessários, $\\frac{N(N-1)}{2}$ preditores. Uma das vantagens é que cada classificador precisa apenas ser treinado em um subconjunto do dataset de treino. Para a previsão, todos os $\\frac{N(N-1)}{2}$ são utilizados e a classe com a maior quantidade de previsões positivas é tomada como a previsão final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQ1r2G2Ka-nT"
   },
   "source": [
    "A grande vantagem do ```scikitlearn``` é que ele detecta quando tenta-se usar um classificador binário para uma tarefa multiclasse. Neste caso, usa-se automáticamente a estratégia OvA (exceto para o algoritmo SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulv_F84Ka-nU"
   },
   "source": [
    "### 7.2. Código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIPtwR3Qa-nU"
   },
   "source": [
    "Para treinar nosso estimador multiclasse, vamos usar o dataset MNIST, que contém imagens de dígitos numéricos de 0 a 9 escritos a mão.\n",
    "\n",
    "Este conjunto de dados é largamente conhecido e utilizado. O objetivo é prever o digito a partir da imagem fornecida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpcYbgpxa-nV"
   },
   "source": [
    "<center>\n",
    "\n",
    "![MNIST](https://miro.medium.com/max/584/1*2lSjt9YKJn9sxK7DSeGDyw.jpeg)\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3JbEUG0a-nX"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  digits.data, digits.target, stratify=digits.target, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D94U2vj-3OK0"
   },
   "source": [
    "Note que as imagens tem dimensão 8x8 pixels, o que corresponde a 64 variáveis/features diferentes (onde cada pixel é uma variável independente diferente). E quanto maior o valor da variável, mais claro é o tom daquele pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "executionInfo": {
     "elapsed": 573,
     "status": "ok",
     "timestamp": 1604503246055,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "dR7AESgDuX_B",
    "outputId": "faf9f44a-3dfd-4f37-866e-4eb295412060"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Mostrar exemplo de amostra\n",
    "print(X_test[5].reshape(8, -1))\n",
    "_ = plt.imshow(X_test[5].reshape(8, -1), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKsNX8Lya-na"
   },
   "source": [
    "Inicialmente usaremos um modelo linear chamado SGD, que utiliza como treinamento o método de gradiente descendente (o mesmo usado para treinar redes neurais), mas a escolha pode ser qualquer outra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 685,
     "status": "ok",
     "timestamp": 1604503162671,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "xk70GWpRa-nb",
    "outputId": "62b9983c-f2f7-4b7d-add4-142e43b00c36"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 520,
     "status": "ok",
     "timestamp": 1604503162672,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "pD3MljWIa-nf",
    "outputId": "ab9443c4-3581-4f0d-e56d-128b2b05c2b4"
   },
   "outputs": [],
   "source": [
    "# Testar uma previsão\n",
    "print('Resposta: ', y_test[5])\n",
    "print('Previsão: ', sgd_clf.predict(X_test[5].reshape(1,-1))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F69Fe3uKa-nk"
   },
   "source": [
    "Simples, não? O código já encapsula e abstrai todo a implementação da estratégia de classificação multiclasse usando um preditor binário. Por trás do treino, a biblioteca do ```scikit-learn``` treinou 10 modelos diferentes e os usou para realizar a previsão.\n",
    "\n",
    "Você pode usar a função ```decision_function()``` para retornar todos os scores da previsão das 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 546,
     "status": "ok",
     "timestamp": 1604503164465,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "GO1AB6Ywa-nl",
    "outputId": "e3b9d541-aa17-47c0-8879-c372d0c0ad70"
   },
   "outputs": [],
   "source": [
    "digit_score = sgd_clf.decision_function(X_test[5].reshape(1, -1))\n",
    "digit_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dQTn4a3a-nq"
   },
   "source": [
    "Nele é possível ver que o maior score realmente pertence à classe 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jlwXUYEa-nq"
   },
   "source": [
    "Caso deseje forçar o ```scikitlearn``` a usar uma estratégia ou outra, você pode usar as classes ```OneVsOneClassifier``` ou ```OneVsRestClassifier```.\n",
    "\n",
    "Basta criar uma instância da classe que implementa a estratégia desejada passando um preditor binário como argumento do método construtor da classe. Abaixo um exemplo que cria um classificador multiclasse usando a estratégia OvO e o preditor SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 569,
     "status": "ok",
     "timestamp": 1604502982953,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "NavQE_hta-nr",
    "outputId": "aa41637f-6db2-4168-8205-b7fd273846b2"
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "ovo_clf = OneVsOneClassifier(SGDClassifier(random_state=42))\n",
    "ovo_clf.fit(X_train, y_train)\n",
    "ovo_clf.predict(X_test[5].reshape(1, -1))\n",
    "len(ovo_clf.estimators_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XrM_ZNlfa-ny"
   },
   "source": [
    "Podemos ver que o número de estimadores treinados corresponde à formula\n",
    "\n",
    "$\\frac{(10(10-1))}{2}$ = 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4bX07SVa-ny"
   },
   "source": [
    "Vamos agora treinar um modelo de floresta aleatória (random forest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1065,
     "status": "ok",
     "timestamp": 1604503089105,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "n07Ncr0ba-nz",
    "outputId": "59d7756d-6f93-4197-93b2-8fc320bf2568"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "forest_clf.fit(X_train, y_train)\n",
    "forest_clf.predict(X_test[5].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGuL39KUa-n2"
   },
   "source": [
    "Neste caso, como o Random Forest é um algoritmo que implementa a classificação multiclasse por natureza, não há a necessidade de rodar uma das estratégias OvA ou OvO. \n",
    "\n",
    "Você pode chamar a função ```predict_proba()``` para obter a lista de probabilidades que o classificador atribuiu para cada instância e cada classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 855,
     "status": "ok",
     "timestamp": 1604503702596,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "zcnFQ2jsa-n3",
    "outputId": "501a0126-2fb9-4f7e-80a5-2496d45eee7c"
   },
   "outputs": [],
   "source": [
    "forest_clf.predict_proba(X_test[5].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tToPHGa8a-n-"
   },
   "source": [
    "Podemos ver que o preditor é suficientemente confiante de sua previsão, atribuindo aproximadamente 90% de probabilidade da amostra ser um dígito 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSLw97iMa-n_"
   },
   "source": [
    "### 7.3. Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHM7mKhDa-oB"
   },
   "source": [
    "Agora, podemos analisar a performance do preditor usando as funções ```cross_val_score()``` e ```confusion_matrix()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1254,
     "status": "ok",
     "timestamp": 1604504408620,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "R14k_TNBa-oC",
    "outputId": "2c1ac6c0-935c-48b1-b348-798527716a05"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train, cv=3)\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    "conf_mx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRdU5A_ia-oF"
   },
   "source": [
    "Como estamos tratando com 10 classes, a quantidade de métricas acaba dificultando a visualização. Uma maneira mais visual de avaliar neste caso é vendo a matriz como imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "executionInfo": {
     "elapsed": 600,
     "status": "ok",
     "timestamp": 1604504527770,
     "user": {
      "displayName": "Felipe Takaoka",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgWa1X5kLEs7LLPCPOFDMnVIyhsbVLKGCwGUkJt=s64",
      "userId": "03689138148573572734"
     },
     "user_tz": 180
    },
    "id": "f3e0mpuXa-oG",
    "outputId": "112e9543-0fa1-49a6-86e8-9639de32263c"
   },
   "outputs": [],
   "source": [
    "plt.matshow(conf_mx,cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsZ9I0q2a-oK"
   },
   "source": [
    "Como a grande maioria dos valores se encontra na diagonal principal, as previsões estão corretas e pode-se concluir que o \n",
    "desempenho do modelo está bom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukmp7epea-oK"
   },
   "source": [
    "#### Exercício 7.1\n",
    "\n",
    "Implemente um modelo SVM para a tarefa de multiclassificação e imprima o número de estimadores criados usando a estratégia OvA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "exid": "7.1",
    "id": "JxQRIgL0a-oM"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import ______\n",
    "\n",
    "ova_clf = _________(_______(gamma='auto'))\n",
    "ova_clf.___(X_train, y_train)\n",
    "ova_clf.___(X_test[20].reshape(1, -1))\n",
    "\n",
    "n_estimadores = len(ova_clf._____________)\n",
    "print(n_estimadores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCTZvFT1a-oQ"
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rRLNIjISa-oS"
   },
   "source": [
    "<a id=\"digdeeper\"></a>\n",
    "## 8. Dig Deeper\n",
    "\n",
    "* [Multi-Class Text Classification with Scikit-Learn](https://towardsdatascience.com/multi-class-text-classification-with-scikit-learn-12f1e60e0a9f)\n",
    "* [Music Genre Classification with Python](https://towardsdatascience.com/music-genre-classification-with-python-c714d032f0d8)\n",
    "* [XGBoost Algorithm: Long May She Reign!](https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d)\n",
    "* [Fine-tuning XGBoost in Python like a boss](https://towardsdatascience.com/fine-tuning-xgboost-in-python-like-a-boss-b4543ed8b1e)\n",
    "* [An interesting and intuitive view of AUC and ROC curve](https://towardsdatascience.com/an-interesting-and-intuitive-view-of-auc-5f6498d87328)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEMBRE-SE DE SALVAR O NOTEBOOK ANTES DE EXECUTAR ESSA CÉLULA\n",
    "token = '<SEU TOKEN AQUI>' # seu token aqui\n",
    " \n",
    "# Não altere o código \tabaixo\n",
    "import requests as req\n",
    "exec(req.get('https://api.vai.academy/submissioncode').text)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "colab": {
   "collapsed_sections": [
    "_6JFzme_a-j_",
    "DdApfy1ra-kA",
    "AdipCyGSa-kB",
    "FCMQ_FOMa-kH",
    "VRvVVj6ya-kP",
    "ImK_Cy8Aa-kP",
    "eF9heQHja-kU",
    "dS1PWUaoa-kw",
    "XSNAbQksa-kx",
    "nFoQ_nBEa-k3",
    "cU8Ifgl3a-ll",
    "acv0GwhQa-lm",
    "8D8V-HiOa-lu",
    "0hVlC2mta-md",
    "VPf-21UBa-mi",
    "_tpDir97a-mj",
    "Y85oq_OZa-mk",
    "ncjXP4HYa-mt",
    "XALKaGTva-nO",
    "ulv_F84Ka-nU",
    "rSLw97iMa-n_",
    "ukmp7epea-oK"
   ],
   "name": "Classificação.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "207px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
